<!DOCTYPE html>
<html xmlns:cc="http://creativecommons.org/ns#"><head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# medium-com: http://ogp.me/ns/fb/medium-com#"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=contain"><title>Contextual Bandits and Reinforcement Learning – Towards Data Science</title><link rel="canonical" href="https://towardsdatascience.com/contextual-bandits-and-reinforcement-learning-6bdfeaece72a"><meta name="title" content="Contextual Bandits and Reinforcement Learning – Towards Data Science"><meta name="referrer" content="always"><meta name="description" content="If you develop personalization of user experience for your website or an app, contextual bandits can help you. Using contextual bandits, you can choose which content to display to the user, rank…"><meta name="theme-color" content="#000000"><meta property="og:title" content="Contextual Bandits and Reinforcement Learning – Towards Data Science"><meta property="og:url" content="https://towardsdatascience.com/contextual-bandits-and-reinforcement-learning-6bdfeaece72a"><meta property="og:image" content="https://cdn-images-1.medium.com/max/1200/1*FH4t-DcuKWfLYRWvd4JIjA.png"><meta property="fb:app_id" content="542599432471018"><meta property="og:description" content="If you develop personalization of user experience for your website or an app, contextual bandits can help you. Using contextual bandits…"><meta name="twitter:description" content="If you develop personalization of user experience for your website or an app, contextual bandits can help you. Using contextual bandits…"><meta name="twitter:image:src" content="https://cdn-images-1.medium.com/max/1200/1*FH4t-DcuKWfLYRWvd4JIjA.png"><link rel="publisher" href="https://plus.google.com/103654360130207659246"><link rel="author" href="https://towardsdatascience.com/@surmenok"><meta property="author" content="Pavel Surmenok"><meta property="og:type" content="article"><meta name="twitter:card" content="summary_large_image"><meta property="article:publisher" content="https://www.facebook.com/towardsdatascience"><meta property="article:author" content="970668082998286"><meta name="robots" content="index, follow"><meta property="article:published_time" content="2017-08-27T01:17:22.072Z"><meta name="twitter:creator" content="@surmenok"><meta name="twitter:site" content="@TDataScience"><meta property="og:site_name" content="Towards Data Science"><meta name="twitter:label1" value="Reading time"><meta name="twitter:data1" value="6 min read"><meta name="twitter:app:name:iphone" content="Medium"><meta name="twitter:app:id:iphone" content="828256236"><meta name="twitter:app:url:iphone" content="medium://p/6bdfeaece72a"><meta property="al:ios:app_name" content="Medium"><meta property="al:ios:app_store_id" content="828256236"><meta property="al:android:package" content="com.medium.reader"><meta property="al:android:app_name" content="Medium"><meta property="al:ios:url" content="medium://p/6bdfeaece72a"><meta property="al:android:url" content="medium://p/6bdfeaece72a"><meta property="al:web:url" content="https://towardsdatascience.com/contextual-bandits-and-reinforcement-learning-6bdfeaece72a"><link rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://towardsdatascience.com/osd.xml"><link rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/6bdfeaece72a"><script type="application/ld+json">{"@context":"http://schema.org","@type":"NewsArticle","image":{"@type":"ImageObject","width":586,"height":465,"url":"https://cdn-images-1.medium.com/max/586/1*FH4t-DcuKWfLYRWvd4JIjA.png"},"datePublished":"2017-08-27T01:17:22.072Z","dateModified":"2018-04-20T03:08:52.087Z","headline":"Contextual Bandits and Reinforcement Learning","name":"Contextual Bandits and Reinforcement Learning","keywords":["Machine Learning","Artificial Intelligence","Deep Learning","AI","Data Science"],"author":{"@type":"Person","name":"Pavel Surmenok","url":"https://towardsdatascience.com/@surmenok"},"creator":["Pavel Surmenok"],"publisher":{"@type":"Organization","name":"Towards Data Science","url":"https://towardsdatascience.com","logo":{"@type":"ImageObject","width":308,"height":60,"url":"https://cdn-images-1.medium.com/max/308/1*OMF3fSqH8t4xBJ9-6oZDZw.png"}},"mainEntityOfPage":"https://towardsdatascience.com/contextual-bandits-and-reinforcement-learning-6bdfeaece72a"}</script><link rel="stylesheet" type="text/css" id="glyph-8" href="Contextual%20Bandits%20and%20Reinforcement%20Learning%20%E2%80%93%20Towards%20Data%20Science_files/m2.css"><link rel="stylesheet" href="Contextual%20Bandits%20and%20Reinforcement%20Learning%20%E2%80%93%20Towards%20Data%20Science_files/main-branding-base.css"><script>if (window.top !== window.self) window.top.location = window.self.location.href;var OB_startTime = new Date().getTime(); var OB_loadErrors = []; function _onerror(e) { OB_loadErrors.push(e) }; if (document.addEventListener) document.addEventListener("error", _onerror, true); else if (document.attachEvent) document.attachEvent("onerror", _onerror); function _asyncScript(u) {var d = document, f = d.getElementsByTagName("script")[0], s = d.createElement("script"); s.type = "text/javascript"; s.async = true; s.src = u; f.parentNode.insertBefore(s, f);}function _asyncStyles(u) {var d = document, f = d.getElementsByTagName("script")[0], s = d.createElement("link"); s.rel = "stylesheet"; s.href = u; f.parentNode.insertBefore(s, f); return s}(new Image()).src = "/_/stat?event=pixel.load&origin=" + encodeURIComponent(location.origin);</script><script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date; ga("create", "UA-24232453-2", "auto", {"allowLinker": true, "legacyCookieDomain": window.location.hostname}); ga("send", "pageview");ga("create", "UA-19707169-24", "auto", 'tracker0'); ga("tracker0.send", "pageview");</script><script async="" src="Contextual%20Bandits%20and%20Reinforcement%20Learning%20%E2%80%93%20Towards%20Data%20Science_files/analytics.js"></script><!--[if lt IE 9]><script charset="UTF-8" src="https://cdn-static-1.medium.com/_/fp/js/shiv.RI2ePTZ5gFmMgLzG5bEVAA.js"></script><![endif]--><link rel="icon" href="https://cdn-images-1.medium.com/fit/c/128/128/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg" class="js-favicon"><link rel="apple-touch-icon" sizes="152x152" href="https://cdn-images-1.medium.com/fit/c/304/304/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg"><link rel="apple-touch-icon" sizes="120x120" href="https://cdn-images-1.medium.com/fit/c/240/240/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg"><link rel="apple-touch-icon" sizes="76x76" href="https://cdn-images-1.medium.com/fit/c/152/152/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg"><link rel="apple-touch-icon" sizes="60x60" href="Contextual%20Bandits%20and%20Reinforcement%20Learning%20%E2%80%93%20Towards%20Data%20Science_files/1F0LADxTtsKOgmPa-_7iUEQ.jpeg"><link rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg" color="#171717"></head><body itemscope="" class="postShowScreen browser-firefox is-withMagicUnderlines v-glyph v-glyph--m2 is-js" data-action-scope="_actionscope_0"><script>document.body.className = document.body.className.replace(/(^|\s)is-noJs(\s|$)/, "$1is-js$2")</script><div class="site-main surface-container" id="container"><div class="butterBar butterBar--privacy" data-action-scope="_actionscope_1"><div class="butterBar-message"><div class="u-flexCenter u-justifyContentSpaceBetween u-paddingVertical12 u-maxWidth1000"><div class="u-flex1"><span class="u-xs-hide">Medium uses browser cookies to give you the best possible experience. <span class="u-sm-show"><br></span></span>By using Medium, you agree to our <a class=" link--underline" href="https://medium.com/policy/f03bf92035c9" target="_blank">Privacy Policy</a>.</div><div class="u-flex0 u-textAlignRight u-marginLeft10"><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon" data-action="butter-bar-dismiss"><span class="svgIcon svgIcon--removeThin svgIcon--19px"><svg class="svgIcon-use" width="19" height="19" viewBox="0 0 19 19"><path d="M13.792 4.6l-4.29 4.29-4.29-4.29-.612.613 4.29 4.29-4.29 4.29.613.612 4.29-4.29 4.29 4.29.612-.613-4.29-4.29 4.29-4.29" fill-rule="evenodd"></path></svg></span></button></div></div></div></div><div class="surface" id="_obv.shell._surface_1524663454406" style="display: block; visibility: visible;"><div class="screenContent surface-content is-supplementalPostContentLoaded" data-used="true" data-action-scope="_actionscope_2"><canvas class="canvas-renderer" width="1088" height="558"></canvas><div class="container u-maxWidth740 u-xs-margin0 notesPositionContainer js-notesPositionContainer"><div class="notesMarkers" data-action-scope="_actionscope_4"><div class="paragraphControls js-paragraphControl js-paragraphControl-9e1b u-noUserSelect is-visible" style="top: 5913px;"><span class="paragraphControls-itemText"><button class="button button--chromeless" data-action="select-anchor" data-action-value="9e1b">Top highlight</button></span></div></div></div><div class="metabar u-clearfix js-metabar u-textColorTransparentWhiteDarker u-fixed u-backgroundTransparentWhiteDarkest u-xs-sizeFullViewportWidth u-tintBgColor u-tintSpectrum"><div class="js-metabarMiddle metabar-inner u-marginAuto u-maxWidth1000 u-flexCenter u-justifyContentSpaceBetween u-height65 u-xs-height56 u-paddingLeft20 u-paddingRight20"><div class="metabar-block u-flex1  u-flexCenter"><div class="js-metabarLogoLeft"><a href="https://medium.com/" data-log-event="home" class="siteNav-logo u-flexCenter u-paddingTop0"><span class="svgIcon svgIcon--logoMonogram svgIcon--45px is-flushLeft u-textColorDarker"><svg class="svgIcon-use" width="45" height="45" viewBox="0 0 45 45"><path d="M5 40V5h35v35H5zm8.56-12.627c0 .555-.027.687-.318 1.03l-2.457 2.985v.396h6.974v-.396l-2.456-2.985c-.291-.343-.344-.502-.344-1.03V18.42l6.127 13.364h.714l5.256-13.364v10.644c0 .29 0 .342-.185.528l-1.848 1.796v.396h9.19v-.396l-1.822-1.796c-.184-.186-.21-.238-.21-.528V15.937c0-.291.026-.344.21-.528l1.823-1.797v-.396h-6.471l-4.622 11.542-5.203-11.542h-6.79v.396l2.14 2.64c.239.292.291.37.291.768v10.353z"></path></svg></span><span class="u-textScreenReader">Homepage</span></a></div><div class="u-alignMiddle u-inlineBlock u-verticalAlignTop u-height65 u-xs-height56"><div class="u-alignBlock"><span class="u-inlineBlock u-height28 u-xs-height24 u-verticalAlignTop u-marginRight20 u-marginLeft15 u-borderRightTransparentWhiteLighter"></span></div></div><div class="u-alignMiddle u-inlineBlock u-verticalAlignTop u-height65 u-xs-height56 u-marginRight18"><div class="u-alignBlock"><a class="js-collectionLogoOrName" href="https://towardsdatascience.com/?source=logo-lo_sL5hrCPWk201---7f60cf5620c9"><span class="u-inlineBlock u-uiTextBold u-fontSize18 u-lineHeight18 u-xs-fontSize22 u-xs-lineHeight22 u-xs-noWrapWithEllipsis u-xs-maxWidth200">Towards Data Science</span></a></div></div><div class="u-alignMiddle u-inlineBlock u-verticalAlignTop u-height65 u-xs-height56 u-xs-hide"><div class="u-alignBlock"><div class="buttonSet"><button class="button button--primary button--smallest u-noUserSelect button--withChrome u-accentColor--buttonNormal js-relationshipButton is-smallPill" data-action="sign-up-prompt" data-sign-in-action="toggle-follow-collection" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/collection/towards-data-science" data-action-source="----7f60cf5620c9----------------------follow_header" data-collection-id="7f60cf5620c9"><span class="button-label  js-buttonLabel">Follow</span></button><a class="button button--light button--chromeless is-touchIconBlackPulse u-baseColor--buttonLight button--withIcon button--withSvgIcon" href="https://twitter.com/TDataScience" title="Visit “Towards Data Science” on Twitter" aria-label="Visit “Towards Data Science” on Twitter" rel="me" target="_blank"><span class="button-defaultState"><span class="svgIcon svgIcon--twitterFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M21.725 5.338c-.744.47-1.605.804-2.513 1.006a3.978 3.978 0 0 0-2.942-1.293c-2.22 0-4.02 1.81-4.02 4.02 0 .32.034.63.07.94-3.31-.18-6.27-1.78-8.255-4.23a4.544 4.544 0 0 0-.574 2.01c.04 1.43.74 2.66 1.8 3.38-.63-.01-1.25-.19-1.79-.5v.08c0 1.93 1.38 3.56 3.23 3.95-.34.07-.7.12-1.07.14-.25-.02-.5-.04-.72-.07.49 1.58 1.97 2.74 3.74 2.8a8.49 8.49 0 0 1-5.02 1.72c-.3-.03-.62-.04-.93-.07A11.447 11.447 0 0 0 8.88 21c7.386 0 11.43-6.13 11.414-11.414.015-.21.01-.38 0-.578a7.604 7.604 0 0 0 2.01-2.08 7.27 7.27 0 0 1-2.297.645 3.856 3.856 0 0 0 1.72-2.23"></path></svg></span></span></a><a class="button button--light button--chromeless is-touchIconBlackPulse u-baseColor--buttonLight button--withIcon button--withSvgIcon u-paddingLeft0" href="https://facebook.com/towardsdatascience" title="Visit “Towards Data Science” on Facebook" aria-label="Visit “Towards Data Science” on Facebook" rel="me" target="_blank"><span class="button-defaultState"><span class="svgIcon svgIcon--facebookFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M21 12.646C21 7.65 16.97 3.6 12 3.6s-9 4.05-9 9.046a9.026 9.026 0 0 0 7.59 8.924v-6.376H8.395V12.64h2.193v-1.88c0-2.186 1.328-3.375 3.267-3.375.93 0 1.728.07 1.96.1V9.77H14.47c-1.055 0-1.26.503-1.26 1.242v1.63h2.517l-.33 2.554H13.21V21.6c4.398-.597 7.79-4.373 7.79-8.954"></path></svg></span></span></a></div></div></div></div><div class="metabar-block u-flex0 u-flexCenter"><div class="u-alignMiddle u-inlineBlock u-verticalAlignTop u-height65 u-xs-height56"><div class="u-alignBlock"><div class="buttonSet buttonSet--wide u-lineHeightInherit"><a class="button button--primary button--light button--chromeless u-accentColor--buttonNormal is-inSiteNavBar u-xs-hide js-signInButton" href="https://medium.com/m/signin?redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontextual-bandits-and-reinforcement-learning-6bdfeaece72a&amp;source=--------------------------nav_reg&amp;operation=login" data-action="sign-in-prompt" data-redirect="https://towardsdatascience.com/contextual-bandits-and-reinforcement-learning-6bdfeaece72a" data-action-source="--------------------------nav_reg">Sign in</a><a class="button button--primary button--light button--withChrome u-accentColor--buttonNormal is-inSiteNavBar js-signUpButton" href="https://medium.com/m/signin?redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcontextual-bandits-and-reinforcement-learning-6bdfeaece72a&amp;source=--------------------------nav_reg&amp;operation=register" data-action="sign-up-prompt" data-redirect="https://towardsdatascience.com/contextual-bandits-and-reinforcement-learning-6bdfeaece72a" data-action-source="--------------------------nav_reg">Get started</a></div></div></div></div></div><div class="metabar-inner u-marginAuto u-maxWidth1000 js-metabarBottom"><nav role="navigation" class="metabar-block metabar-block--below u-overflowHidden u-height44"><ul class="u-textAlignLeft u-noWrap u-overflowX u-paddingBottom100 u-sm-paddingLeft20 u-sm-paddingRight20 js-collectionNavItems"><li class="metabar-navItem js-collectionNavItem u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken u-baseColor--link js-homeNav" href="https://towardsdatascience.com/">Home</a></li><li class="metabar-navItem js-collectionNavItem  u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/data-science/home">Data Science</a></li><li class="metabar-navItem js-collectionNavItem  u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/machine-learning/home">Machine Learning</a></li><li class="metabar-navItem js-collectionNavItem  u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/programming/home">Programming</a></li><li class="metabar-navItem js-collectionNavItem  u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/data-visualization/home">Visualization</a></li><li class="metabar-navItem js-collectionNavItem  u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/editors-picks/home">Picks</a></li><li class="metabar-navItem js-collectionNavItem  u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="link link--darken u-accentColor--textDarken link--noUnderline u-baseColor--link js-navItemLink" href="https://towardsdatascience.com/contribute/home">Contribute</a></li><li class="metabar-navItem js-collectionNavItem u-uiTextMedium u-fontSize14 u-inlineBlock u-textUppercase u-letterSpacing003 u-textColorNormal u-xs-paddingRight12 u-xs-marginRight0 u-paddingTop5 u-xs-paddingTop10"><a class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon u-top1" href="https://towardsdatascience.com/search" title="Search" aria-label="Search"><span class="button-defaultState"><span class="svgIcon svgIcon--search svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M20.067 18.933l-4.157-4.157a6 6 0 1 0-.884.884l4.157 4.157a.624.624 0 1 0 .884-.884zM6.5 11c0-2.62 2.13-4.75 4.75-4.75S16 8.38 16 11s-2.13 4.75-4.75 4.75S6.5 13.62 6.5 11z"></path></svg></span></span></a></li></ul></nav></div></div><div class="metabar metabar--spacer js-metabarSpacer u-tintBgColor  u-height105 u-xs-height95"></div><main role="main"><article class=" u-minHeight100vhOffset65 u-overflowHidden postArticle postArticle--full is-withAccentColors u-marginBottom40" lang="en"><header class="container u-maxWidth740"><div class="uiScale uiScale-ui--regular uiScale-caption--regular postMetaHeader u-paddingBottom10 row"><div class="col u-size12of12 js-postMetaLockup"><div class="uiScale uiScale-ui--regular uiScale-caption--regular postMetaLockup postMetaLockup--authorWithBio u-flexCenter js-postMetaLockup"><div class="u-flex0"><a class="link u-baseColor--link avatar" href="https://towardsdatascience.com/@surmenok?source=post_header_lockup" data-action="show-user-card" data-action-source="post_header_lockup" data-action-value="d002f056f8c" data-action-type="hover" data-user-id="d002f056f8c" data-collection-slug="towards-data-science" dir="auto"><img src="Contextual%20Bandits%20and%20Reinforcement%20Learning%20%E2%80%93%20Towards%20Data%20Science_files/0Er1PaJU1KWzERL6w.jpeg" class="avatar-image avatar-image--small" alt="Go to the profile of Pavel Surmenok"></a></div><div class="u-flex1 u-paddingLeft15 u-overflowHidden"><div class="u-lineHeightTightest"><a class="ds-link ds-link--styleSubtle ui-captionStrong u-inlineBlock link link--darken link--darker" href="https://towardsdatascience.com/@surmenok?source=post_header_lockup" data-action="show-user-card" data-action-source="post_header_lockup" data-action-value="d002f056f8c" data-action-type="hover" data-user-id="d002f056f8c" data-collection-slug="towards-data-science" dir="auto">Pavel Surmenok</a><span class="followState js-followState" data-user-id="d002f056f8c"><button class="button button--smallest u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton u-marginLeft10 u-xs-hide" data-action="sign-up-prompt" data-sign-in-action="toggle-block-user" data-requires-token="true" data-redirect="https://towardsdatascience.com/contextual-bandits-and-reinforcement-learning-6bdfeaece72a" data-action-source="post_header_lockup"><span class="button-label  button-defaultState">Blocked</span><span class="button-label button-hoverState">Unblock</span></button><button class="button button--primary button--smallest u-noUserSelect button--withChrome u-accentColor--buttonNormal button--follow js-followButton u-marginLeft10 u-xs-hide" data-action="sign-up-prompt" data-sign-in-action="toggle-subscribe-user" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/user/d002f056f8c" data-action-source="post_header_lockup-d002f056f8c-------------------------follow_byline"><span class="button-label  button-defaultState js-buttonLabel">Follow</span><span class="button-label button-activeState">Following</span></button></span></div><div class="ui-caption ui-xs-clamp2 postMetaInline">Engineering Manager at JustAnswer. Machine learning engineering and chatbots. All opinions are my own.</div><div class="ui-caption postMetaInline js-testPostMetaInlineSupplemental"><time datetime="2017-08-27T01:17:22.072Z">Aug 26, 2017</time><span class="middotDivider u-fontSize12"></span><span class="readingTime" title="6 min read"></span></div></div></div></div></div></header><div class="postArticle-content js-postField js-notesSource js-trackedPost" data-post-id="6bdfeaece72a" data-source="post_page" data-collection-id="7f60cf5620c9" data-tracking-context="postPage" data-scroll="native"><section name="3a6b" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h1 name="4dc5" id="4dc5" class="graf graf--h3 graf--leading graf--title">Contextual Bandits and Reinforcement Learning</h1><figure name="7090" id="7090" class="graf graf--figure graf-after--h3"><div class="aspectRatioPlaceholder is-locked" style="max-width: 586px; max-height: 465px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 79.4%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*FH4t-DcuKWfLYRWvd4JIjA.png" data-width="586" data-height="465" data-is-featured="true" data-scroll="native"><img src="Contextual%20Bandits%20and%20Reinforcement%20Learning%20%E2%80%93%20Towards%20Data%20Science_files/1FH4t-DcuKWfLYRWvd4JIjA_002.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="58"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*FH4t-DcuKWfLYRWvd4JIjA.png" src="Contextual%20Bandits%20and%20Reinforcement%20Learning%20%E2%80%93%20Towards%20Data%20Science_files/1FH4t-DcuKWfLYRWvd4JIjA.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*FH4t-DcuKWfLYRWvd4JIjA.png"></noscript></div></div><figcaption class="imageCaption">Source: <a href="https://blog.iterable.com/why-you-should-become-a-multi-armed-bandit-1cb6651063f5" data-href="https://blog.iterable.com/why-you-should-become-a-multi-armed-bandit-1cb6651063f5" class="markup--anchor markup--figure-anchor" rel="nofollow noopener" target="_blank">https://blog.iterable.com/why-you-should-become-a-multi-armed-bandit-1cb6651063f5</a></figcaption></figure><p name="d2fa" id="d2fa" class="graf graf--p graf-after--figure">If
 you develop personalization of user experience for your website or an 
app, contextual bandits can help you. Using contextual bandits, you can 
choose which content to display to the user, rank advertisements, 
optimize search results, select the best image to show on the page, and 
much more.</p><p name="121a" id="121a" class="graf graf--p graf-after--p">There
 are many names for this class of algorithms: contextual bandits, 
multi-world testing, associative bandits, learning with partial 
feedback, learning with bandit feedback, bandits with side information, 
multi-class classification with bandit feedback, associative 
reinforcement learning, one-step reinforcement learning.</p><p name="366c" id="366c" class="graf graf--p graf-after--p graf--trailing">Researchers
 approach the problem from two different angles. You can think about 
contextual bandits as an extension of multi-armed bandits, or as a 
simplified version of reinforcement learning.</p></div></div></section><section name="160a" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="1660" id="1660" class="graf graf--p graf--startsWithDoubleQuote graf--leading">“Bandit”
 in “multi-armed bandits” comes from “one-armed bandit” machines used in
 a casino. Imagine that you are in a casino with many one-armed bandit 
machines. Each machine has a different probability of a win. Your goal 
is to maximize total payout. You can pull a limited number of arms, and 
you don’t know which bandit to use to get the best payout. The problem 
involves exploration/exploitation tradeoff: you should balance between 
trying different bandits to learn more about an expected payout of every
 machine, but you also want to exploit the best bandit you know about 
more. This problem has many real-world applications, including website 
optimization, clinical trials, adaptive routing and financial portfolio 
design. You can think about it as smarter A/B testing.</p><p name="795e" id="795e" class="graf graf--p graf-after--p">The
 multi-armed bandit algorithm outputs an action but doesn’t use any 
information about the state of the environment (context). For example, 
if you use a multi-armed bandit to choose whether to display cat images 
or dog images to the user of your website, you’ll make the same random 
decision even if you know something about preferences of the user. The 
contextual bandit extends the model by making the decision conditional 
on the state of the environment.</p><figure name="58be" id="58be" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 224px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 31.900000000000002%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*HH9PGI9dThtu6BpJtLmABg.png" data-width="1788" data-height="571" data-action="zoom" data-action-value="1*HH9PGI9dThtu6BpJtLmABg.png" data-scroll="native"><img src="Contextual%20Bandits%20and%20Reinforcement%20Learning%20%E2%80%93%20Towards%20Data%20Science_files/1HH9PGI9dThtu6BpJtLmABg_002.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="23"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*HH9PGI9dThtu6BpJtLmABg.png" src="Contextual%20Bandits%20and%20Reinforcement%20Learning%20%E2%80%93%20Towards%20Data%20Science_files/1HH9PGI9dThtu6BpJtLmABg.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*HH9PGI9dThtu6BpJtLmABg.png"></noscript></div></div><figcaption class="imageCaption">Source: <a href="https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0" data-href="https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0" class="markup--anchor markup--figure-anchor" rel="nofollow" target="_blank">https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0</a></figcaption></figure><p name="b372" id="b372" class="graf graf--p graf-after--figure">With
 such model, you not only optimize decision based on previous 
observations, but you also personalize decisions for every situation. 
You will show an image of a cat to a cat person, and an image of a dog 
to a dog person, you may show different images at different times of the
 day and days of the week.</p><p name="6600" id="6600" class="graf graf--p graf-after--p">The
 algorithm observes a context, makes a decision, choosing one action 
from a number of alternative actions, and observes an outcome of that 
decision. An outcome defines a reward. The goal is to maximize average 
reward.</p><p name="3bc3" id="3bc3" class="graf graf--p graf-after--p">For
 example, you can use a contextual bandit to select which news article 
to show first on the main page of your website to optimize click through
 rate. The context is information about the user: where they come from, 
previously visited pages of the site, device information, geolocation, 
etc. An action is a choice of what news article to display. An outcome 
is whether the user clicked on a link or not. A reward is binary: 0 if 
there is no click, 1 if there is a click.</p><p name="6e63" id="6e63" class="graf graf--p graf-after--p graf--trailing">If
 we would have reward values for every possible action for every 
example, we could just use any classification algorithm, using context 
data as features and action with the best reward as a label. The 
challenge is that we don’t know which action is the best, we have only 
partial information: reward value for the action which was used in the 
example. You still can use machine learning models for this, but you’ll 
have to change the cost function. A naïve implementation is to try to 
predict the reward.</p></div></div></section><section name="b062" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="cf04" id="cf04" class="graf graf--p graf--leading"><a href="https://github.com/Microsoft/mwt-ds/raw/master/images/MWT-WhitePaper.pdf" data-href="https://github.com/Microsoft/mwt-ds/raw/master/images/MWT-WhitePaper.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Microsoft published a whitepaper</a>
 with an overview of the methodology and description of their 
implementation of a multi-world testing service. This service is being 
developed by Microsoft Research group in New York. Previously, many of 
the researchers in that group were working in that field at Yahoo. 
Microsoft Multi-world testing service uses Vowpal Wabbit, an open source
 library that implements online and offline training algorithms for 
contextual bandits. Offline training and evaluation algorithms is 
described in the paper “<a href="https://arxiv.org/pdf/1103.4601.pdf" data-href="https://arxiv.org/pdf/1103.4601.pdf" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Doubly Robust Policy Evaluation and Learning</a>” (Miroslav Dudik, John Langford, Lihong Li).</p><blockquote name="9d2e" id="9d2e" class="graf graf--blockquote graf--startsWithDoubleQuote graf-after--p">“Two
 kinds of approaches address offline learning in contextual bandits. The
 first, which we call the direct method (DM), estimates the reward 
function from given data and uses this estimate in place of actual 
reward to evaluate the policy value on a set of contexts. The second 
kind, called inverse propensity score (IPS) (Horvitz &amp; Thompson, 
1952), uses importance weighting to correct for the incorrect 
proportions of actions in the historic data. The first approach requires
 an accurate model of rewards, whereas the second approach requires an 
accurate model of the past policy. In general, it might be difficult to 
accurately model rewards, so the first assumption can be too 
restrictive. On the other hand, it is usually possible to model the past
 policy quite well. However, the second kind of approach often suffers 
from large variance especially when the past policy differs 
significantly from the policy being evaluated.</blockquote><blockquote name="cd5a" id="cd5a" class="graf graf--blockquote graf-after--blockquote">In
 this paper, we propose to use the technique of doubly robust (DR) 
estimation to overcome problems with the two existing approaches. Doubly
 robust (or doubly protected) estimation (Cassel et al., 1976; Robins et
 al., 1994; Robins &amp; Rotnitzky, 1995; Lunceford &amp; Davidian, 
2004; Kang &amp; Schafer, 2007) is a statistical approach for estimation
 from incomplete data with an important property: if either one of the 
two estimators (in DM and IPS) is correct, then the estimation is 
unbiased. This method thus increases the chances of drawing reliable 
inference. “</blockquote><p name="ce83" id="ce83" class="graf graf--p graf-after--blockquote">A couple of video tutorials on contextual bandits:</p><p name="c1b1" id="c1b1" class="graf graf--p graf-after--p"><a href="http://hunch.net/~exploration_learning/" data-href="http://hunch.net/~exploration_learning/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">ICML and KDD 2010 Tutorial on Learning through Exploration</a></p><p name="13d5" id="13d5" class="graf graf--p graf-after--p"><a href="http://www.cs.cornell.edu/~adith/CfactSIGIR2016/" data-href="http://www.cs.cornell.edu/~adith/CfactSIGIR2016/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">SIGIR 2016 Tutorial on Counterfactual Evaluation and Learning for Search, Recommendation and Ad Placement</a></p><p name="e03b" id="e03b" class="graf graf--p graf-after--p"><a href="http://videolectures.net/kdd2010_beygelzimer_langford_lte/" data-href="http://videolectures.net/kdd2010_beygelzimer_langford_lte/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Learning through Exploration</a></p><p name="bec6" id="bec6" class="graf graf--p graf-after--p graf--trailing">And you can find a lot of links to other resources <a href="https://livingthing.danmackinlay.name/bandit_problems.html" data-href="https://livingthing.danmackinlay.name/bandit_problems.html" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">here</a>.</p></div></div></section><section name="64ef" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="e397" id="e397" class="graf graf--p graf--leading">You can think about reinforcement learning as an extension of contextual bandits.</p><figure name="261c" id="261c" class="graf graf--figure graf-after--p"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 295px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 42.1%;"></div><div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded" data-image-id="1*TcA7ske9sdMcXuXTn68-9A.png" data-width="1761" data-height="741" data-action="zoom" data-action-value="1*TcA7ske9sdMcXuXTn68-9A.png" data-scroll="native"><img src="Contextual%20Bandits%20and%20Reinforcement%20Learning%20%E2%80%93%20Towards%20Data%20Science_files/1TcA7ske9sdMcXuXTn68-9A_002.png" crossorigin="anonymous" class="progressiveMedia-thumbnail js-progressiveMedia-thumbnail"><canvas class="progressiveMedia-canvas js-progressiveMedia-canvas" width="75" height="31"></canvas><img class="progressiveMedia-image js-progressiveMedia-image" data-src="https://cdn-images-1.medium.com/max/1600/1*TcA7ske9sdMcXuXTn68-9A.png" src="Contextual%20Bandits%20and%20Reinforcement%20Learning%20%E2%80%93%20Towards%20Data%20Science_files/1TcA7ske9sdMcXuXTn68-9A.png"><noscript class="js-progressiveMedia-inner"><img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/1*TcA7ske9sdMcXuXTn68-9A.png"></noscript></div></div><figcaption class="imageCaption">Source: <a href="https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0" data-href="https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0" class="markup--anchor markup--figure-anchor" rel="nofollow" target="_blank">https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0</a></figcaption></figure><p name="149a" id="149a" class="graf graf--p graf-after--figure">You
 still have an agent (policy) that takes actions based on the state of 
the environment, observes a reward. The difference is that the agent can
 take multiple consecutive actions, and reward information is sparse. 
For example, you can train a model to play chess. The model will use the
 state of the chess board as context, will decide on which moves to 
make, but it will get a reward only at the very end of the game: win, 
loss, or draw. The sparsity of reward information makes it harder to 
train the model. You encounter a problem of credit assignment problem: 
how to assign credit or blame individual actions.</p><p name="9850" id="9850" class="graf graf--p graf-after--p">There
 are many variations of reinforcement learning algorithms. One of the 
extensions of reinforcement learning is deep reinforcement learning. It 
uses a deep neural network as a part of the system.</p><p name="50bb" id="50bb" class="graf graf--p graf-after--p graf--trailing">Arthur Juliani wrote a nice <a href="https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0" data-href="https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0" class="markup--anchor markup--p-anchor" target="_blank">tutorial on reinforcement learning with Tensorflow</a>.</p></div></div></section><section name="84b4" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="9e1b" id="9e1b" class="graf graf--p graf--leading">Researchers
 interested in contextual bandits seem to focus more on creating 
algorithms that have better statistical qualities, for example, regret 
guarantees. <span class="markup--quote markup--p-quote is-other" name="anon_4e74ec4327a" data-creator-ids="anon">Regret
 is an expected difference between an expectation of the sum of rewards 
when using an optimal policy and the sum of collected rewards using the 
contextual bandit policy learned from data.</span> Some classes of algorithms have theoretical guarantees on upper bound of regret.</p><p name="959f" id="959f" class="graf graf--p graf-after--p graf--trailing">Researchers
 interested in reinforcement learning seem to be more interested in 
applying machine learning algorithms to new problems: robotics, 
self-driving cars, inventory management, trading systems. They often 
focus on the development of algorithms that can improve state of the art
 for some set of problems.</p></div></div></section><section name="fd2e" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="2f47" id="2f47" class="graf graf--p graf--leading graf--trailing">Technical
 approaches are also different. Microsoft Multiworld Testing Whitepaper 
describes training algorithm that uses a negative IPS (inverse 
propensity score) as a loss function. Minimizing the loss function will 
lead to maximization of IPS estimator. I couldn’t find anybody using IPS
 estimator in reinforcement learning algorithms. If you get 
reinforcement learning algorithm with policy gradients and simplify it 
to a contextual bandit by reducing a number of steps to one, the model 
will be very similar to a supervised classification model. For the loss 
function, you will use cross-entropy but multiply by the reward value.</p></div></div></section><section name="e395" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="ec8b" id="ec8b" class="graf graf--p graf--leading graf--trailing">It
 was interesting to compare two different classes of algorithms which 
converge in a narrow area of the contextual bandits. I could miss 
something as I haven’t dig deep into theoretical foundations yet. Please
 let me know if you notice any mistakes of missing details in this 
article.</p></div></div></section><section name="d4a8" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="9c73" id="9c73" class="graf graf--p graf--leading">See also:</p><p name="1344" id="1344" class="graf graf--p graf-after--p"><a href="https://medium.com/@surmenok/best-sources-of-deep-learning-news-fbc98815bad3" data-href="https://medium.com/@surmenok/best-sources-of-deep-learning-news-fbc98815bad3" class="markup--anchor markup--p-anchor" target="_blank">Best Sources of Deep Learning News</a></p><p name="869d" id="869d" class="graf graf--p graf-after--p"><a href="https://becominghuman.ai/jeff-deans-talk-on-large-scale-deep-learning-171fb8c8ac57" data-href="https://becominghuman.ai/jeff-deans-talk-on-large-scale-deep-learning-171fb8c8ac57" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Jeff Dean’s Talk on Large-Scale Deep Learning</a></p><p name="948f" id="948f" class="graf graf--p graf-after--p graf--trailing"><a href="https://medium.com/@surmenok/character-level-convolutional-networks-for-text-classification-d582c0c36ace" data-href="https://medium.com/@surmenok/character-level-convolutional-networks-for-text-classification-d582c0c36ace" class="markup--anchor markup--p-anchor" target="_blank">Character-level Convolutional Networks for Text Classification</a></p></div></div></section><section name="e798" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="2c61" id="2c61" class="graf graf--p graf--leading graf--trailing"><em class="markup--em markup--p-em">The article was originally published on </em><a href="http://pavel.surmenok.com/2017/08/26/contextual-bandits-and-reinforcement-learning/" data-href="http://pavel.surmenok.com/2017/08/26/contextual-bandits-and-reinforcement-learning/" class="markup--anchor markup--p-anchor" rel="nofollow noopener noopener" target="_blank"><em class="markup--em markup--p-em">http://pavel.surmenok.com/2017/08/26/contextual-bandits-and-reinforcement-learning/</em></a></p></div></div></section></div><footer class="u-paddingTop10"><div class="container u-maxWidth740"><div class="row"><div class="col u-size12of12"></div></div><div class="row"><div class="col u-size12of12 js-postTags"><div class="u-paddingBottom10"><ul class="tags tags--postTags tags--borderless"><li><a class="link u-baseColor--link" href="https://towardsdatascience.com/tagged/machine-learning?source=post" data-action-source="post" data-collection-slug="towards-data-science">Machine Learning</a></li><li><a class="link u-baseColor--link" href="https://towardsdatascience.com/tagged/artificial-intelligence?source=post" data-action-source="post" data-collection-slug="towards-data-science">Artificial Intelligence</a></li><li><a class="link u-baseColor--link" href="https://towardsdatascience.com/tagged/deep-learning?source=post" data-action-source="post" data-collection-slug="towards-data-science">Deep Learning</a></li><li><a class="link u-baseColor--link" href="https://towardsdatascience.com/tagged/ai?source=post" data-action-source="post" data-collection-slug="towards-data-science">AI</a></li><li><a class="link u-baseColor--link" href="https://towardsdatascience.com/tagged/data-science?source=post" data-action-source="post" data-collection-slug="towards-data-science">Data Science</a></li></ul></div></div></div><section class="uiScale uiScale-ui--small uiScale-caption--regular u-borderTopLightest u-marginTop10 u-paddingTop20"><div class="ui-h3 u-textColorDarker u-fontSize22">One clap, two clap, three clap, forty?</div><p class="ui-body u-marginBottom20 u-textColorDark u-fontSize16">By clapping more or less, you can signal to us which stories really stand out.</p></section><div class="postActions js-postActionsFooter"><div class="u-flexCenter"><div class="u-flex1"><div class="multirecommend js-actionMultirecommend u-flexCenter u-width60" data-post-id="6bdfeaece72a" data-is-icon-29px="true" data-is-circle="true" data-has-recommend-list="true" data-source="post_actions_footer-----6bdfeaece72a---------------------clap_footer"><div class="u-relative u-foreground"><button class="button button--large button--circle button--withChrome u-baseColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--largePill u-relative u-foreground u-xs-paddingLeft13 u-width60 u-height60 u-accentColor--textNormal u-accentColor--buttonNormal clap-onboardingcollection" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/6bdfeaece72a" data-action-source="post_actions_footer-----6bdfeaece72a---------------------clap_footer" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33" viewBox="0 0 33 33"><path d="M28.86 17.342l-3.64-6.402c-.292-.433-.712-.729-1.163-.8a1.124 1.124 0 0 0-.889.213c-.63.488-.742 1.181-.33 2.061l1.222 2.587 1.4 2.46c2.234 4.085 1.511 8.007-2.145 11.663-.26.26-.526.49-.797.707 1.42-.084 2.881-.683 4.292-2.094 3.822-3.823 3.565-7.876 2.05-10.395zm-6.252 11.075c3.352-3.35 3.998-6.775 1.978-10.469l-3.378-5.945c-.292-.432-.712-.728-1.163-.8a1.122 1.122 0 0 0-.89.213c-.63.49-.742 1.182-.33 2.061l1.72 3.638a.502.502 0 0 1-.806.568l-8.91-8.91a1.335 1.335 0 0 0-1.887 1.886l5.292 5.292a.5.5 0 0 1-.707.707l-5.292-5.292-1.492-1.492c-.503-.503-1.382-.505-1.887 0a1.337 1.337 0 0 0 0 1.886l1.493 1.492 5.292 5.292a.499.499 0 0 1-.353.854.5.5 0 0 1-.354-.147L5.642 13.96a1.338 1.338 0 0 0-1.887 0 1.338 1.338 0 0 0 0 1.887l2.23 2.228 3.322 3.324a.499.499 0 0 1-.353.853.502.502 0 0 1-.354-.146l-3.323-3.324a1.333 1.333 0 0 0-1.886 0 1.325 1.325 0 0 0-.39.943c0 .356.138.691.39.943l6.396 6.397c3.528 3.53 8.86 5.313 12.821 1.353zM12.73 9.26l5.68 5.68-.49-1.037c-.518-1.107-.426-2.13.224-2.89l-3.303-3.304a1.337 1.337 0 0 0-1.886 0 1.326 1.326 0 0 0-.39.944c0 .217.067.42.165.607zm14.787 19.184c-1.599 1.6-3.417 2.392-5.353 2.392-.349 0-.7-.03-1.058-.082a7.922 7.922 0 0 1-3.667.887c-3.049 0-6.115-1.626-8.359-3.87l-6.396-6.397A2.315 2.315 0 0 1 2 19.724a2.327 2.327 0 0 1 1.923-2.296l-.875-.875a2.339 2.339 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.647l-.139-.139c-.91-.91-.91-2.39 0-3.3.884-.884 2.421-.882 3.301 0l.138.14a2.335 2.335 0 0 1 3.948-1.24l.093.092c.091-.423.291-.828.62-1.157a2.336 2.336 0 0 1 3.3 0l3.384 3.386a2.167 2.167 0 0 1 1.271-.173c.534.086 1.03.354 1.441.765.11-.549.415-1.034.911-1.418a2.12 2.12 0 0 1 1.661-.41c.727.117 1.385.565 1.853 1.262l3.652 6.423c1.704 2.832 2.025 7.377-2.205 11.607zM13.217.484l-1.917.882 2.37 2.837-.454-3.719zm8.487.877l-1.928-.86-.44 3.697 2.368-2.837zM16.5 3.293L15.478-.005h2.044L16.5 3.293z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33" viewBox="0 0 33 33"><g fill-rule="evenodd"><path d="M29.58 17.1l-3.854-6.78c-.365-.543-.876-.899-1.431-.989a1.491 1.491 0 0 0-1.16.281c-.42.327-.65.736-.7 1.207v.001l3.623 6.367c2.46 4.498 1.67 8.802-2.333 12.807-.265.265-.536.505-.81.728 1.973-.222 3.474-1.286 4.45-2.263 4.166-4.165 3.875-8.6 2.215-11.36zm-4.831.82l-3.581-6.3c-.296-.439-.725-.742-1.183-.815a1.105 1.105 0 0 0-.89.213c-.647.502-.755 1.188-.33 2.098l1.825 3.858a.601.601 0 0 1-.197.747.596.596 0 0 1-.77-.067L10.178 8.21c-.508-.506-1.393-.506-1.901 0a1.335 1.335 0 0 0-.393.95c0 .36.139.698.393.95v.001l5.61 5.61a.599.599 0 1 1-.848.847l-5.606-5.606c-.001 0-.002 0-.003-.002L5.848 9.375a1.349 1.349 0 0 0-1.902 0 1.348 1.348 0 0 0 0 1.901l1.582 1.582 5.61 5.61a.6.6 0 0 1-.848.848l-5.61-5.61c-.51-.508-1.393-.508-1.9 0a1.332 1.332 0 0 0-.394.95c0 .36.139.697.393.952l2.363 2.362c.002.001.002.002.002.003l3.52 3.52a.6.6 0 0 1-.848.847l-3.522-3.523h-.001a1.336 1.336 0 0 0-.95-.393 1.345 1.345 0 0 0-.949 2.295l6.779 6.78c3.715 3.713 9.327 5.598 13.49 1.434 3.527-3.528 4.21-7.13 2.086-11.015zM11.817 7.727c.06-.328.213-.64.466-.893.64-.64 1.755-.64 2.396 0l3.232 3.232c-.82.783-1.09 1.833-.764 2.992l-5.33-5.33z"></path><path d="M13.285.48l-1.916.881 2.37 2.837z"></path><path d="M21.719 1.361L19.79.501l-.44 3.697z"></path><path d="M16.502 3.298L15.481 0h2.043z"></path></g></svg></span></span></button><div class="clapUndo u-width60 u-round u-height32 u-absolute u-borderBox u-paddingRight5 u-transition--transform200Spring u-background--brandSageLighter js-clapUndo" style="top: 14px; padding: 2px;"><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon u-floatRight" data-action="multivote-undo" data-action-value="6bdfeaece72a"><span class="svgIcon svgIcon--removeThin svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M20.13 8.11l-5.61 5.61-5.609-5.61-.801.801 5.61 5.61-5.61 5.61.801.8 5.61-5.609 5.61 5.61.8-.801-5.609-5.61 5.61-5.61" fill-rule="evenodd"></path></svg></span></button></div></div><span class="u-textAlignCenter u-relative u-background js-actionMultirecommendCount u-marginLeft10"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton" data-action="show-recommends" data-action-value="6bdfeaece72a">200</button></span></div></div><div class="buttonSet u-flex0"><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon" data-action="scroll-to-responses" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--response svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M21.27 20.058c1.89-1.826 2.754-4.17 2.754-6.674C24.024 8.21 19.67 4 14.1 4 8.53 4 4 8.21 4 13.384c0 5.175 4.53 9.385 10.1 9.385 1.007 0 2-.14 2.95-.41.285.25.592.49.918.7 1.306.87 2.716 1.31 4.19 1.31.276-.01.494-.14.6-.36a.625.625 0 0 0-.052-.65c-.61-.84-1.042-1.71-1.282-2.58a5.417 5.417 0 0 1-.154-.75zm-3.85 1.324l-.083-.28-.388.12a9.72 9.72 0 0 1-2.85.424c-4.96 0-8.99-3.706-8.99-8.262 0-4.556 4.03-8.263 8.99-8.263 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32c0 .07 0 .19.02.37.03.29.1.6.19.92.19.7.49 1.4.89 2.08-.93-.14-1.83-.49-2.67-1.06-.34-.22-.88-.48-1.16-.74z"></path></svg></span></button><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon u-xs-hide" title="Share on Twitter" aria-label="Share on Twitter" data-action="share-on-twitter" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--twitter svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M21.967 11.8c.018 5.93-4.607 11.18-11.177 11.18-2.172 0-4.25-.62-6.047-1.76l-.268.422-.038.5.186.013.168.012c.3.02.44.032.6.046 2.06-.026 3.95-.686 5.49-1.86l1.12-.85-1.4-.048c-1.57-.055-2.92-1.08-3.36-2.51l-.48.146-.05.5c.22.03.48.05.75.08.48-.02.87-.07 1.25-.15l2.33-.49-2.32-.49c-1.68-.35-2.91-1.83-2.91-3.55 0-.05 0-.01-.01.03l-.49-.1-.25.44c.63.36 1.35.57 2.07.58l1.7.04L7.4 13c-.978-.662-1.59-1.79-1.618-3.047a4.08 4.08 0 0 1 .524-1.8l-.825.07a12.188 12.188 0 0 0 8.81 4.515l.59.033-.06-.59v-.02c-.05-.43-.06-.63-.06-.87a3.617 3.617 0 0 1 6.27-2.45l.2.21.28-.06c1.01-.22 1.94-.59 2.73-1.09l-.75-.56c-.1.36-.04.89.12 1.36.23.68.58 1.13 1.17.85l-.21-.45-.42-.27c-.52.8-1.17 1.48-1.92 2L22 11l.016.28c.013.2.014.35 0 .52v.04zm.998.038c.018-.22.017-.417 0-.66l-.498.034.284.41a8.183 8.183 0 0 0 2.2-2.267l.97-1.48-1.6.755c.17-.08.3-.02.34.03a.914.914 0 0 1-.13-.292c-.1-.297-.13-.64-.1-.766l.36-1.254-1.1.695c-.69.438-1.51.764-2.41.963l.48.15a4.574 4.574 0 0 0-3.38-1.484 4.616 4.616 0 0 0-4.61 4.613c0 .29.02.51.08.984l.01.02.5-.06.03-.5c-3.17-.18-6.1-1.7-8.08-4.15l-.48-.56-.36.64c-.39.69-.62 1.48-.65 2.28.04 1.61.81 3.04 2.06 3.88l.3-.92c-.55-.02-1.11-.17-1.6-.45l-.59-.34-.14.67c-.02.08-.02.16 0 .24-.01 2.12 1.55 4.01 3.69 4.46l.1-.49-.1-.49c-.33.07-.67.12-1.03.14-.18-.02-.43-.05-.64-.07l-.76-.09.23.73c.57 1.84 2.29 3.14 4.28 3.21l-.28-.89a8.252 8.252 0 0 1-4.85 1.66c-.12-.01-.26-.02-.56-.05l-.17-.01-.18-.01L2.53 21l1.694 1.07a12.233 12.233 0 0 0 6.58 1.917c7.156 0 12.2-5.73 12.18-12.18l-.002.04z"></path></svg></span></button><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon u-xs-hide" title="Share on Facebook" aria-label="Share on Facebook" data-action="share-on-facebook" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--facebook svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M16.39 23.61v-5.808h1.846a.55.55 0 0 0 .546-.48l.36-2.797a.551.551 0 0 0-.547-.62H16.39V12.67c0-.67.12-.813.828-.813h1.474a.55.55 0 0 0 .55-.55V8.803a.55.55 0 0 0-.477-.545c-.436-.06-1.36-.116-2.22-.116-2.5 0-4.13 1.62-4.13 4.248v1.513H10.56a.551.551 0 0 0-.55.55v2.797c0 .304.248.55.55.55h1.855v5.76c-4.172-.96-7.215-4.7-7.215-9.1 0-5.17 4.17-9.36 9.31-9.36 5.14 0 9.31 4.19 9.31 9.36 0 4.48-3.155 8.27-7.43 9.15M14.51 4C8.76 4 4.1 8.684 4.1 14.46c0 5.162 3.75 9.523 8.778 10.32a.55.55 0 0 0 .637-.543v-6.985a.551.551 0 0 0-.55-.55H11.11v-1.697h1.855a.55.55 0 0 0 .55-.55v-2.063c0-2.02 1.136-3.148 3.03-3.148.567 0 1.156.027 1.597.06v1.453h-.924c-1.363 0-1.93.675-1.93 1.912v1.78c0 .3.247.55.55.55h2.132l-.218 1.69H15.84c-.305 0-.55.24-.55.55v7.02c0 .33.293.59.623.54 5.135-.7 9.007-5.11 9.007-10.36C24.92 8.68 20.26 4 14.51 4"></path></svg></span></button><button class="button button--large button--dark button--chromeless u-baseColor--buttonDark button--withIcon button--withSvgIcon u-xs-show" title="Share this story on Twitter or Facebook" aria-label="Share this story on Twitter or Facebook" data-action="show-share-popover" data-action-source="post_actions_footer"><span class="svgIcon svgIcon--share svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M20.385 8H19a.5.5 0 1 0 .011 1h1.39c.43 0 .84.168 1.14.473.31.305.48.71.48 1.142v10.77c0 .43-.17.837-.47 1.142-.3.305-.71.473-1.14.473H8.62c-.43 0-.84-.168-1.144-.473a1.603 1.603 0 0 1-.473-1.142v-10.77c0-.43.17-.837.48-1.142A1.599 1.599 0 0 1 8.62 9H10a.502.502 0 0 0 0-1H8.615c-.67 0-1.338.255-1.85.766-.51.51-.765 1.18-.765 1.85v10.77c0 .668.255 1.337.766 1.848.51.51 1.18.766 1.85.766h11.77c.668 0 1.337-.255 1.848-.766.51-.51.766-1.18.766-1.85v-10.77c0-.668-.255-1.337-.766-1.848A2.61 2.61 0 0 0 20.384 8zm-8.67-2.508L14 3.207v8.362c0 .27.224.5.5.5s.5-.23.5-.5V3.2l2.285 2.285a.49.49 0 0 0 .704-.001.511.511 0 0 0 0-.708l-3.14-3.14a.504.504 0 0 0-.71 0L11 4.776a.501.501 0 0 0 .71.706" fill-rule="evenodd"></path></svg></span></button></div></div></div></div><div class="u-maxWidth740 u-paddingTop20 u-marginTop20 u-borderTopLightest container u-paddingBottom20 u-xs-paddingBottom10 js-postAttributionFooterContainer"><div class="row js-postFooterInfo"><div class="col u-size6of12 u-xs-size12of12"><li class="uiScale uiScale-ui--small uiScale-caption--regular u-block u-paddingBottom18 js-cardUser"><div class="u-marginLeft20 u-floatRight"><span class="followState js-followState" data-user-id="d002f056f8c"><button class="button button--small u-noUserSelect button--withChrome u-baseColor--buttonNormal button--withHover button--unblock js-unblockButton" data-action="sign-up-prompt" data-sign-in-action="toggle-block-user" data-requires-token="true" data-redirect="https://towardsdatascience.com/contextual-bandits-and-reinforcement-learning-6bdfeaece72a" data-action-source="footer_card"><span class="button-label  button-defaultState">Blocked</span><span class="button-label button-hoverState">Unblock</span></button><button class="button button--primary button--small u-noUserSelect button--withChrome u-accentColor--buttonNormal button--follow js-followButton" data-action="sign-up-prompt" data-sign-in-action="toggle-subscribe-user" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/user/d002f056f8c" data-action-source="footer_card-d002f056f8c-------------------------follow_footer"><span class="button-label  button-defaultState js-buttonLabel">Follow</span><span class="button-label button-activeState">Following</span></button></span></div><div class="u-tableCell"><a class="link u-baseColor--link avatar" href="https://towardsdatascience.com/@surmenok?source=footer_card" title="Go to the profile of Pavel Surmenok" aria-label="Go to the profile of Pavel Surmenok" data-action-source="footer_card" data-user-id="d002f056f8c" data-collection-slug="towards-data-science" dir="auto"><img src="Contextual%20Bandits%20and%20Reinforcement%20Learning%20%E2%80%93%20Towards%20Data%20Science_files/0Er1PaJU1KWzERL6w.jpeg" class="avatar-image avatar-image--small" alt="Go to the profile of Pavel Surmenok"></a></div><div class="u-tableCell u-verticalAlignMiddle u-breakWord u-paddingLeft15"><h3 class="ui-h3 u-fontSize18 u-lineHeightTighter u-marginBottom4"><a class="link link--primary u-accentColor--hoverTextNormal" href="https://towardsdatascience.com/@surmenok" property="cc:attributionName" title="Go to the profile of Pavel Surmenok" aria-label="Go to the profile of Pavel Surmenok" rel="author cc:attributionUrl" data-user-id="d002f056f8c" data-collection-slug="towards-data-science" dir="auto">Pavel Surmenok</a></h3><p class="ui-body u-fontSize14 u-lineHeightBaseSans u-textColorDark u-marginBottom4">Engineering Manager at JustAnswer. Machine learning engineering and chatbots. All opinions are my own.</p></div></li></div><div class="col u-size6of12 u-xs-size12of12 u-xs-marginTop30"><li class="uiScale uiScale-ui--small uiScale-caption--regular u-block u-paddingBottom18 js-cardCollection"><div class="u-marginLeft20 u-floatRight"><button class="button button--primary button--small u-noUserSelect button--withChrome u-accentColor--buttonNormal js-relationshipButton" data-action="sign-up-prompt" data-sign-in-action="toggle-follow-collection" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/collection/towards-data-science" data-action-source="----7f60cf5620c9----------------------follow_footer" data-collection-id="7f60cf5620c9"><span class="button-label  js-buttonLabel">Follow</span></button></div><div class="u-tableCell "><a class="link u-baseColor--link avatar avatar--roundedRectangle" href="https://towardsdatascience.com/?source=footer_card" title="Go to Towards Data Science" aria-label="Go to Towards Data Science" data-action-source="footer_card" data-collection-slug="towards-data-science"><img src="Contextual%20Bandits%20and%20Reinforcement%20Learning%20%E2%80%93%20Towards%20Data%20Science_files/1F0LADxTtsKOgmPa-_7iUEQ.jpeg" class="avatar-image u-size60x60" alt="Towards Data Science"></a></div><div class="u-tableCell u-verticalAlignMiddle u-breakWord u-paddingLeft15"><h3 class="ui-h3 u-fontSize18 u-lineHeightTighter u-marginBottom4"><a class="link link--primary u-accentColor--hoverTextNormal" href="https://towardsdatascience.com/?source=footer_card" rel="collection" data-action-source="footer_card" data-collection-slug="towards-data-science">Towards Data Science</a></h3><p class="ui-body u-fontSize14 u-lineHeightBaseSans u-textColorDark u-marginBottom4">Sharing concepts, ideas, and codes.</p><div class="buttonSet"></div></div></li></div></div></div><div class="js-postFooterPlacements"><div class="streamItem streamItem--placementCardGrid js-streamItem"><div class="u-clearfix u-backgroundGrayLightest"><div class="row u-marginAuto u-maxWidth1000 u-paddingTop30 u-paddingBottom40"><div class="col u-padding8 u-xs-size12of12 u-size4of12"><div class="uiScale uiScale-ui--small uiScale-caption--regular u-height280 u-sizeFullWidth u-backgroundWhite u-borderCardBorder u-boxShadow u-borderBox u-borderRadius4 js-trackedPost" data-post-id="2d1594c74ce0" data-source="placement_card_footer_grid---------0-41" data-tracking-context="placement" data-scroll="native"><a class="link link--noUnderline u-baseColor--link" href="https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0?source=placement_card_footer_grid---------0-41" data-action-source="placement_card_footer_grid---------0-41"><div class="u-backgroundCover u-backgroundColorGrayLight u-height100 u-sizeFullWidth u-borderBottomLight u-borderRadiusTop4" style="background-image: url(&quot;https://cdn-images-1.medium.com/fit/c/400/120/1*Fr-q6mQNYjJr6hTglTic7g.jpeg&quot;); background-position: 50% 50% !important;"></div></a><div class="u-padding15 u-borderBox u-flexColumn u-height180"><a class="link link--noUnderline u-baseColor--link u-flex1" href="https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0?source=placement_card_footer_grid---------0-41" data-action-source="placement_card_footer_grid---------0-41"><div class="uiScale uiScale-ui--regular uiScale-caption--small u-textColorNormal u-marginBottom7">More from Towards Data Science</div><div class="ui-h3 ui-clamp2 u-textColorDarkest u-contentSansBold u-fontSize24 u-maxHeight2LineHeightTighter u-lineClamp2 u-textOverflowEllipsis u-letterSpacingTight u-paddingBottom2">The fall of RNN / LSTM</div></a><div class="u-paddingBottom10 u-flex0 u-flexCenter"><div class="u-flex1 u-minWidth0 u-marginRight10"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://towardsdatascience.com/@culurciello" data-action="show-user-card" data-action-value="e53b1a2a902f" data-action-type="hover" data-user-id="e53b1a2a902f" data-collection-slug="towards-data-science" dir="auto"><img src="Contextual%20Bandits%20and%20Reinforcement%20Learning%20%E2%80%93%20Towards%20Data%20Science_files/0aFGtSUa46IEvCxLI.jpeg" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Eugenio Culurciello"></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--darker" href="https://towardsdatascience.com/@culurciello?source=placement_card_footer_grid---------0-41" data-action="show-user-card" data-action-source="placement_card_footer_grid---------0-41" data-action-value="e53b1a2a902f" data-action-type="hover" data-user-id="e53b1a2a902f" data-collection-slug="towards-data-science" dir="auto">Eugenio Culurciello</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><span class="readingTime u-textColorNormal" title="8 min read"></span></div></div></div></div><div class="u-flex0 u-flexCenter"><div class="buttonSet"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="2d1594c74ce0" data-is-label-padded="true" data-source="placement_card_footer_grid-----2d1594c74ce0----0-41----------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/2d1594c74ce0" data-action-source="placement_card_footer_grid-----2d1594c74ce0----0-41----------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-textAlignCenter u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents u-marginLeft4" data-action="show-recommends" data-action-value="2d1594c74ce0">4.1K</button></span></div></div><div class="u-height20 u-borderRightLighter u-inlineBlock u-relative u-marginRight10 u-marginLeft12"></div><div class="buttonSet"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/2d1594c74ce0" data-action-source="placement_card_footer_grid-----2d1594c74ce0----0-41----------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div></div></div><div class="col u-padding8 u-xs-size12of12 u-size4of12"><div class="uiScale uiScale-ui--small uiScale-caption--regular u-height280 u-sizeFullWidth u-backgroundWhite u-borderCardBorder u-boxShadow u-borderBox u-borderRadius4 js-trackedPost" data-post-id="9ec80d148d27" data-source="placement_card_footer_grid---------1-41" data-tracking-context="placement" data-scroll="native"><a class="link link--noUnderline u-baseColor--link" href="https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27?source=placement_card_footer_grid---------1-41" data-action-source="placement_card_footer_grid---------1-41"><div class="u-backgroundCover u-backgroundColorGrayLight u-height100 u-sizeFullWidth u-borderBottomLight u-borderRadiusTop4" style="background-image: url(&quot;https://cdn-images-1.medium.com/fit/c/400/120/1*T7XtvWyesmYAXM0Y9Jv2Gw.jpeg&quot;); background-position: 50% 50% !important;"></div></a><div class="u-padding15 u-borderBox u-flexColumn u-height180"><a class="link link--noUnderline u-baseColor--link u-flex1" href="https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27?source=placement_card_footer_grid---------1-41" data-action-source="placement_card_footer_grid---------1-41"><div class="uiScale uiScale-ui--regular uiScale-caption--small u-textColorNormal u-marginBottom7">More from Towards Data Science</div><div class="ui-h3 ui-clamp2 u-textColorDarkest u-contentSansBold u-fontSize24 u-maxHeight2LineHeightTighter u-lineClamp2 u-textOverflowEllipsis u-letterSpacingTight u-paddingBottom2">Interpretable Machine Learning with XGBoost</div></a><div class="u-paddingBottom10 u-flex0 u-flexCenter"><div class="u-flex1 u-minWidth0 u-marginRight10"><div class="u-flexCenter"><div class="postMetaInline-avatar u-flex0"><a class="link u-baseColor--link avatar" href="https://towardsdatascience.com/@scottmlundberg" data-action="show-user-card" data-action-value="3a739af9ef3a" data-action-type="hover" data-user-id="3a739af9ef3a" data-collection-slug="towards-data-science" dir="auto"><img src="Contextual%20Bandits%20and%20Reinforcement%20Learning%20%E2%80%93%20Towards%20Data%20Science_files/1SD3hMVq2yKA5BoxDIOp-AA.jpeg" class="avatar-image u-size36x36 u-xs-size32x32" alt="Go to the profile of Scott Lundberg"></a></div><div class="postMetaInline postMetaInline-authorLockup ui-captionStrong u-flex1 u-noWrapWithEllipsis"><a class="ds-link ds-link--styleSubtle link link--darken link--darker" href="https://towardsdatascience.com/@scottmlundberg?source=placement_card_footer_grid---------1-41" data-action="show-user-card" data-action-source="placement_card_footer_grid---------1-41" data-action-value="3a739af9ef3a" data-action-type="hover" data-user-id="3a739af9ef3a" data-collection-slug="towards-data-science" dir="auto">Scott Lundberg</a><div class="ui-caption u-fontSize12 u-baseColor--textNormal u-textColorNormal js-postMetaInlineSupplemental"><span class="readingTime u-textColorNormal" title="10 min read"></span></div></div></div></div><div class="u-flex0 u-flexCenter"><div class="buttonSet"><div class="multirecommend js-actionMultirecommend u-flexCenter" data-post-id="9ec80d148d27" data-is-label-padded="true" data-source="placement_card_footer_grid-----9ec80d148d27----1-41----------------clap_preview"><div class="u-relative u-foreground"><button class="button button--primary button--chromeless u-accentColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/9ec80d148d27" data-action-source="placement_card_footer_grid-----9ec80d148d27----1-41----------------clap_preview" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.739 0l.761 2.966L13.261 0z"></path><path d="M14.815 3.776l1.84-2.551-1.43-.471z"></path><path d="M8.378 1.224l1.84 2.551L9.81.753z"></path><path d="M20.382 21.622c-1.04 1.04-2.115 1.507-3.166 1.608.168-.14.332-.29.492-.45 2.885-2.886 3.456-5.982 1.69-9.211l-1.101-1.937-.955-2.02c-.315-.676-.235-1.185.245-1.556a.836.836 0 0 1 .66-.16c.342.056.66.28.879.605l2.856 5.023c1.179 1.962 1.379 5.119-1.6 8.098m-13.29-.528l-5.02-5.02a1 1 0 0 1 .707-1.701c.255 0 .512.098.707.292l2.607 2.607a.442.442 0 0 0 .624-.624L4.11 14.04l-1.75-1.75a.998.998 0 1 1 1.41-1.413l4.154 4.156a.44.44 0 0 0 .624 0 .44.44 0 0 0 0-.624l-4.152-4.153-1.172-1.171a.998.998 0 0 1 0-1.41 1.018 1.018 0 0 1 1.41 0l1.172 1.17 4.153 4.152a.437.437 0 0 0 .624 0 .442.442 0 0 0 0-.624L6.43 8.222a.988.988 0 0 1-.291-.705.99.99 0 0 1 .29-.706 1 1 0 0 1 1.412 0l6.992 6.993a.443.443 0 0 0 .71-.501l-1.35-2.856c-.315-.676-.235-1.185.246-1.557a.85.85 0 0 1 .66-.16c.342.056.659.28.879.606L18.628 14c1.573 2.876 1.067 5.545-1.544 8.156-1.396 1.397-3.144 1.966-5.063 1.652-1.713-.286-3.463-1.248-4.928-2.714zM10.99 5.976l2.562 2.562c-.497.607-.563 1.414-.155 2.284l.265.562-4.257-4.257a.98.98 0 0 1-.117-.445c0-.267.104-.517.292-.706a1.023 1.023 0 0 1 1.41 0zm8.887 2.06c-.375-.557-.902-.916-1.486-1.011a1.738 1.738 0 0 0-1.342.332c-.376.29-.61.656-.712 1.065a2.1 2.1 0 0 0-1.095-.562 1.776 1.776 0 0 0-.992.128l-2.636-2.636a1.883 1.883 0 0 0-2.658 0 1.862 1.862 0 0 0-.478.847 1.886 1.886 0 0 0-2.671-.012 1.867 1.867 0 0 0-.503.909c-.754-.754-1.992-.754-2.703-.044a1.881 1.881 0 0 0 0 2.658c-.288.12-.605.288-.864.547a1.884 1.884 0 0 0 0 2.659l.624.622a1.879 1.879 0 0 0-.91 3.16l5.019 5.02c1.595 1.594 3.515 2.645 5.408 2.959a7.16 7.16 0 0 0 1.173.098c1.026 0 1.997-.24 2.892-.7.279.04.555.065.828.065 1.53 0 2.969-.628 4.236-1.894 3.338-3.338 3.083-6.928 1.738-9.166l-2.868-5.043z"></path></g></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.738 0l.762 2.966L13.262 0z"></path><path d="M16.634 1.224l-1.432-.47-.408 3.022z"></path><path d="M9.79.754l-1.431.47 1.84 2.552z"></path><path d="M22.472 13.307l-3.023-5.32c-.287-.426-.689-.705-1.123-.776a1.16 1.16 0 0 0-.911.221c-.297.231-.474.515-.535.84.017.022.036.04.053.063l2.843 5.001c1.95 3.564 1.328 6.973-1.843 10.144a8.46 8.46 0 0 1-.549.501c1.205-.156 2.328-.737 3.351-1.76 3.268-3.268 3.041-6.749 1.737-8.914"></path><path d="M12.58 9.887c-.156-.83.096-1.569.692-2.142L10.78 5.252c-.5-.504-1.378-.504-1.879 0-.178.18-.273.4-.329.63l4.008 4.005z"></path><path d="M15.812 9.04c-.218-.323-.539-.55-.88-.606a.814.814 0 0 0-.644.153c-.176.137-.713.553-.24 1.566l1.43 3.025a.539.539 0 1 1-.868.612L7.2 6.378a.986.986 0 1 0-1.395 1.395l4.401 4.403a.538.538 0 1 1-.762.762L5.046 8.54 3.802 7.295a.99.99 0 0 0-1.396 0 .981.981 0 0 0 0 1.394L3.647 9.93l4.402 4.403a.537.537 0 0 1 0 .761.535.535 0 0 1-.762 0L2.89 10.696a.992.992 0 0 0-1.399-.003.983.983 0 0 0 0 1.395l1.855 1.854 2.763 2.765a.538.538 0 0 1-.76.761l-2.765-2.764a.982.982 0 0 0-1.395 0 .989.989 0 0 0 0 1.395l5.32 5.32c3.371 3.372 6.64 4.977 10.49 1.126C19.74 19.8 20.271 17 18.62 13.982L15.812 9.04z"></path></g></svg></span></span></button></div><span class="u-textAlignCenter u-relative u-background js-actionMultirecommendCount u-marginLeft5"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-disablePointerEvents u-marginLeft4" data-action="show-recommends" data-action-value="9ec80d148d27">1.5K</button></span></div></div><div class="u-height20 u-borderRightLighter u-inlineBlock u-relative u-marginRight10 u-marginLeft12"></div><div class="buttonSet"><button class="button button--chromeless is-touchIconFadeInPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/9ec80d148d27" data-action-source="placement_card_footer_grid-----9ec80d148d27----1-41----------------bookmark_preview"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126a.508.508 0 0 0 .708-.03.5.5 0 0 0 .118-.285H19V6zm-6.838 9.97L7 19.636V6c0-.55.45-1 1-1h9c.55 0 1 .45 1 1v13.637l-5.162-3.668a.49.49 0 0 0-.676 0z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M19 6c0-1.1-.9-2-2-2H8c-1.1 0-2 .9-2 2v14.66h.012c.01.103.045.204.12.285a.5.5 0 0 0 .706.03L12.5 16.85l5.662 4.126c.205.183.52.17.708-.03a.5.5 0 0 0 .118-.285H19V6z"></path></svg></span></span></button></div></div></div></div></div></div><div class="col u-padding8 u-xs-size12of12 u-size4of12"><div class="u-height280 u-sizeFullWidth u-backgroundWhite u-borderCardBorder u-boxShadow u-borderBox u-borderRadius4"><a href="https://medium.com/s/unrulybodies?source=promo-lo_sL5hrCPWk201--13-----unrulybodies_readnext_041018" data-action="promo-clicked" data-action-value="unrulybodies_readnext_041018"><div class="u-sizeFull u-padding30 u-borderBox u-flexColumn u-borderRadius4 promo-unrulybodies_readnext_041018 js-promo u-backgroundCover u-backgroundNoRepeat" style="background-image:url(https://cdn-images-1.medium.com/max/1400/1*FYpG2pLCXywDvQxoZyBqOQ@2x.png);" data-promo-id="unrulybodies_readnext_041018" data-scroll="native"><div class="uiScale uiScale-ui--large uiScale-caption--regular js-promoText"><div class="u-marginTop20 u-flex"></div></div></div></a></div></div></div></div></div></div><div class="u-padding0 u-clearfix u-backgroundGrayLightest u-print-hide supplementalPostContent js-responsesWrapper" data-action-scope="_actionscope_5"><div class="container u-maxWidth740"><div class="responsesStreamWrapper u-maxWidth640 js-responsesStreamWrapper"><div class="container responsesStream-title u-paddingTop15"><div class="row"><header class="heading"><div class="u-clearfix"><div class="heading-content u-floatLeft"><span class="heading-title heading-title--semibold">Responses</span></div></div></header></div></div><div class="responsesStream-editor cardChromeless u-marginBottom20 u-paddingLeft20 u-paddingRight20 js-responsesStreamEditor"><div class="u-paddingTop30 u-paddingBottom30 u-paddingLeft0 u-paddingRight0 u-borderBottomLightest js-responsesLoggedOutPrompt"><button class="button button--chromeless is-touchIconBlackPulse u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--withIconAndLabel button--loggedOutPrompt" data-action="sign-up-prompt" data-redirect="https://towardsdatascience.com/contextual-bandits-and-reinforcement-learning-6bdfeaece72a#--respond" data-skip-onboarding="true" data-action-source="logged_out_response_prompt--------------------------respond_box"><span class="svgIcon svgIcon--response svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M21.27 20.058c1.89-1.826 2.754-4.17 2.754-6.674C24.024 8.21 19.67 4 14.1 4 8.53 4 4 8.21 4 13.384c0 5.175 4.53 9.385 10.1 9.385 1.007 0 2-.14 2.95-.41.285.25.592.49.918.7 1.306.87 2.716 1.31 4.19 1.31.276-.01.494-.14.6-.36a.625.625 0 0 0-.052-.65c-.61-.84-1.042-1.71-1.282-2.58a5.417 5.417 0 0 1-.154-.75zm-3.85 1.324l-.083-.28-.388.12a9.72 9.72 0 0 1-2.85.424c-4.96 0-8.99-3.706-8.99-8.262 0-4.556 4.03-8.263 8.99-8.263 4.95 0 8.77 3.71 8.77 8.27 0 2.25-.75 4.35-2.5 5.92l-.24.21v.32c0 .07 0 .19.02.37.03.29.1.6.19.92.19.7.49 1.4.89 2.08-.93-.14-1.83-.49-2.67-1.06-.34-.22-.88-.48-1.16-.74z"></path></svg></span><span class="button-label  js-buttonLabel">Write a response…</span></button></div></div><div class="responsesStream js-responsesStream"></div><div class="container u-hide js-showOtherResponses"><div class="row"><button class="button button--primary button--withChrome u-accentColor--buttonNormal responsesStream-showOtherResponses cardChromeless u-sizeFullWidth u-marginVertical20 u-heightAuto" data-action="show-other-responses">Show all responses</button></div></div><div class="responsesStream js-responsesStreamOther"></div></div></div></div><div class="supplementalPostContent js-heroPromo"></div></footer></article></main><aside class="u-marginAuto u-maxWidth1000 js-postLeftSidebar"><div class="u-foreground u-top0 u-fixed u-sm-hide u-marginLeftNegative12 js-postShareWidget u-transition--fadeIn300" data-scroll="fixed" style="transform: translateY(150px);"><ul><li class="u-textAlignCenter u-marginVertical10"><div class="multirecommend js-actionMultirecommend u-flexColumn u-marginBottom10 u-width60" data-post-id="6bdfeaece72a" data-is-icon-29px="true" data-is-vertical="true" data-is-circle="true" data-has-recommend-list="true" data-source="post_share_widget-----6bdfeaece72a---------------------clap_sidebar"><div class="u-relative u-foreground"><button class="button button--large button--circle button--withChrome u-baseColor--buttonNormal button--withIcon button--withSvgIcon clapButton js-actionMultirecommendButton clapButton--largePill u-relative u-foreground u-xs-paddingLeft13 u-width60 u-height60 u-accentColor--textNormal u-accentColor--buttonNormal" data-action="sign-up-prompt" data-sign-in-action="multivote" data-requires-token="true" data-redirect="https://medium.com/_/vote/p/6bdfeaece72a" data-action-source="post_share_widget-----6bdfeaece72a---------------------clap_sidebar" aria-label="Clap"><span class="button-defaultState"><span class="svgIcon svgIcon--clap svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33" viewBox="0 0 33 33"><path d="M28.86 17.342l-3.64-6.402c-.292-.433-.712-.729-1.163-.8a1.124 1.124 0 0 0-.889.213c-.63.488-.742 1.181-.33 2.061l1.222 2.587 1.4 2.46c2.234 4.085 1.511 8.007-2.145 11.663-.26.26-.526.49-.797.707 1.42-.084 2.881-.683 4.292-2.094 3.822-3.823 3.565-7.876 2.05-10.395zm-6.252 11.075c3.352-3.35 3.998-6.775 1.978-10.469l-3.378-5.945c-.292-.432-.712-.728-1.163-.8a1.122 1.122 0 0 0-.89.213c-.63.49-.742 1.182-.33 2.061l1.72 3.638a.502.502 0 0 1-.806.568l-8.91-8.91a1.335 1.335 0 0 0-1.887 1.886l5.292 5.292a.5.5 0 0 1-.707.707l-5.292-5.292-1.492-1.492c-.503-.503-1.382-.505-1.887 0a1.337 1.337 0 0 0 0 1.886l1.493 1.492 5.292 5.292a.499.499 0 0 1-.353.854.5.5 0 0 1-.354-.147L5.642 13.96a1.338 1.338 0 0 0-1.887 0 1.338 1.338 0 0 0 0 1.887l2.23 2.228 3.322 3.324a.499.499 0 0 1-.353.853.502.502 0 0 1-.354-.146l-3.323-3.324a1.333 1.333 0 0 0-1.886 0 1.325 1.325 0 0 0-.39.943c0 .356.138.691.39.943l6.396 6.397c3.528 3.53 8.86 5.313 12.821 1.353zM12.73 9.26l5.68 5.68-.49-1.037c-.518-1.107-.426-2.13.224-2.89l-3.303-3.304a1.337 1.337 0 0 0-1.886 0 1.326 1.326 0 0 0-.39.944c0 .217.067.42.165.607zm14.787 19.184c-1.599 1.6-3.417 2.392-5.353 2.392-.349 0-.7-.03-1.058-.082a7.922 7.922 0 0 1-3.667.887c-3.049 0-6.115-1.626-8.359-3.87l-6.396-6.397A2.315 2.315 0 0 1 2 19.724a2.327 2.327 0 0 1 1.923-2.296l-.875-.875a2.339 2.339 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.647l-.139-.139c-.91-.91-.91-2.39 0-3.3.884-.884 2.421-.882 3.301 0l.138.14a2.335 2.335 0 0 1 3.948-1.24l.093.092c.091-.423.291-.828.62-1.157a2.336 2.336 0 0 1 3.3 0l3.384 3.386a2.167 2.167 0 0 1 1.271-.173c.534.086 1.03.354 1.441.765.11-.549.415-1.034.911-1.418a2.12 2.12 0 0 1 1.661-.41c.727.117 1.385.565 1.853 1.262l3.652 6.423c1.704 2.832 2.025 7.377-2.205 11.607zM13.217.484l-1.917.882 2.37 2.837-.454-3.719zm8.487.877l-1.928-.86-.44 3.697 2.368-2.837zM16.5 3.293L15.478-.005h2.044L16.5 3.293z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--clapFilled svgIcon--33px u-relative u-topNegative2 u-xs-top0"><svg class="svgIcon-use" width="33" height="33" viewBox="0 0 33 33"><g fill-rule="evenodd"><path d="M29.58 17.1l-3.854-6.78c-.365-.543-.876-.899-1.431-.989a1.491 1.491 0 0 0-1.16.281c-.42.327-.65.736-.7 1.207v.001l3.623 6.367c2.46 4.498 1.67 8.802-2.333 12.807-.265.265-.536.505-.81.728 1.973-.222 3.474-1.286 4.45-2.263 4.166-4.165 3.875-8.6 2.215-11.36zm-4.831.82l-3.581-6.3c-.296-.439-.725-.742-1.183-.815a1.105 1.105 0 0 0-.89.213c-.647.502-.755 1.188-.33 2.098l1.825 3.858a.601.601 0 0 1-.197.747.596.596 0 0 1-.77-.067L10.178 8.21c-.508-.506-1.393-.506-1.901 0a1.335 1.335 0 0 0-.393.95c0 .36.139.698.393.95v.001l5.61 5.61a.599.599 0 1 1-.848.847l-5.606-5.606c-.001 0-.002 0-.003-.002L5.848 9.375a1.349 1.349 0 0 0-1.902 0 1.348 1.348 0 0 0 0 1.901l1.582 1.582 5.61 5.61a.6.6 0 0 1-.848.848l-5.61-5.61c-.51-.508-1.393-.508-1.9 0a1.332 1.332 0 0 0-.394.95c0 .36.139.697.393.952l2.363 2.362c.002.001.002.002.002.003l3.52 3.52a.6.6 0 0 1-.848.847l-3.522-3.523h-.001a1.336 1.336 0 0 0-.95-.393 1.345 1.345 0 0 0-.949 2.295l6.779 6.78c3.715 3.713 9.327 5.598 13.49 1.434 3.527-3.528 4.21-7.13 2.086-11.015zM11.817 7.727c.06-.328.213-.64.466-.893.64-.64 1.755-.64 2.396 0l3.232 3.232c-.82.783-1.09 1.833-.764 2.992l-5.33-5.33z"></path><path d="M13.285.48l-1.916.881 2.37 2.837z"></path><path d="M21.719 1.361L19.79.501l-.44 3.697z"></path><path d="M16.502 3.298L15.481 0h2.043z"></path></g></svg></span></span></button><div class="clapUndo u-width60 u-round u-height32 u-absolute u-borderBox u-paddingRight5 u-transition--transform200Spring u-background--brandSageLighter js-clapUndo" style="top: 14px; padding: 2px;"><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon u-floatRight" data-action="multivote-undo" data-action-value="6bdfeaece72a"><span class="svgIcon svgIcon--removeThin svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M20.13 8.11l-5.61 5.61-5.609-5.61-.801.801 5.61 5.61-5.61 5.61.801.8 5.61-5.609 5.61 5.61.8-.801-5.609-5.61 5.61-5.61" fill-rule="evenodd"></path></svg></span></button></div></div><span class="u-textAlignCenter u-relative u-background js-actionMultirecommendCount u-flexOrderNegative1 u-height20 u-marginBottom7"><button class="button button--chromeless u-baseColor--buttonNormal js-multirecommendCountButton u-block u-marginAuto" data-action="show-recommends" data-action-value="6bdfeaece72a">200</button></span></div></li><li class="u-textAlignCenter u-marginVertical10"><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon" title="Share on Twitter" aria-label="Share on Twitter" data-action="share-on-twitter" data-action-source="post_share_widget"><span class="svgIcon svgIcon--twitter svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M21.967 11.8c.018 5.93-4.607 11.18-11.177 11.18-2.172 0-4.25-.62-6.047-1.76l-.268.422-.038.5.186.013.168.012c.3.02.44.032.6.046 2.06-.026 3.95-.686 5.49-1.86l1.12-.85-1.4-.048c-1.57-.055-2.92-1.08-3.36-2.51l-.48.146-.05.5c.22.03.48.05.75.08.48-.02.87-.07 1.25-.15l2.33-.49-2.32-.49c-1.68-.35-2.91-1.83-2.91-3.55 0-.05 0-.01-.01.03l-.49-.1-.25.44c.63.36 1.35.57 2.07.58l1.7.04L7.4 13c-.978-.662-1.59-1.79-1.618-3.047a4.08 4.08 0 0 1 .524-1.8l-.825.07a12.188 12.188 0 0 0 8.81 4.515l.59.033-.06-.59v-.02c-.05-.43-.06-.63-.06-.87a3.617 3.617 0 0 1 6.27-2.45l.2.21.28-.06c1.01-.22 1.94-.59 2.73-1.09l-.75-.56c-.1.36-.04.89.12 1.36.23.68.58 1.13 1.17.85l-.21-.45-.42-.27c-.52.8-1.17 1.48-1.92 2L22 11l.016.28c.013.2.014.35 0 .52v.04zm.998.038c.018-.22.017-.417 0-.66l-.498.034.284.41a8.183 8.183 0 0 0 2.2-2.267l.97-1.48-1.6.755c.17-.08.3-.02.34.03a.914.914 0 0 1-.13-.292c-.1-.297-.13-.64-.1-.766l.36-1.254-1.1.695c-.69.438-1.51.764-2.41.963l.48.15a4.574 4.574 0 0 0-3.38-1.484 4.616 4.616 0 0 0-4.61 4.613c0 .29.02.51.08.984l.01.02.5-.06.03-.5c-3.17-.18-6.1-1.7-8.08-4.15l-.48-.56-.36.64c-.39.69-.62 1.48-.65 2.28.04 1.61.81 3.04 2.06 3.88l.3-.92c-.55-.02-1.11-.17-1.6-.45l-.59-.34-.14.67c-.02.08-.02.16 0 .24-.01 2.12 1.55 4.01 3.69 4.46l.1-.49-.1-.49c-.33.07-.67.12-1.03.14-.18-.02-.43-.05-.64-.07l-.76-.09.23.73c.57 1.84 2.29 3.14 4.28 3.21l-.28-.89a8.252 8.252 0 0 1-4.85 1.66c-.12-.01-.26-.02-.56-.05l-.17-.01-.18-.01L2.53 21l1.694 1.07a12.233 12.233 0 0 0 6.58 1.917c7.156 0 12.2-5.73 12.18-12.18l-.002.04z"></path></svg></span></button></li><li class="u-textAlignCenter u-marginVertical10"><button class="button button--large button--dark button--chromeless is-touchIconBlackPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon" title="Share on Facebook" aria-label="Share on Facebook" data-action="share-on-facebook" data-action-source="post_share_widget"><span class="svgIcon svgIcon--facebook svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M16.39 23.61v-5.808h1.846a.55.55 0 0 0 .546-.48l.36-2.797a.551.551 0 0 0-.547-.62H16.39V12.67c0-.67.12-.813.828-.813h1.474a.55.55 0 0 0 .55-.55V8.803a.55.55 0 0 0-.477-.545c-.436-.06-1.36-.116-2.22-.116-2.5 0-4.13 1.62-4.13 4.248v1.513H10.56a.551.551 0 0 0-.55.55v2.797c0 .304.248.55.55.55h1.855v5.76c-4.172-.96-7.215-4.7-7.215-9.1 0-5.17 4.17-9.36 9.31-9.36 5.14 0 9.31 4.19 9.31 9.36 0 4.48-3.155 8.27-7.43 9.15M14.51 4C8.76 4 4.1 8.684 4.1 14.46c0 5.162 3.75 9.523 8.778 10.32a.55.55 0 0 0 .637-.543v-6.985a.551.551 0 0 0-.55-.55H11.11v-1.697h1.855a.55.55 0 0 0 .55-.55v-2.063c0-2.02 1.136-3.148 3.03-3.148.567 0 1.156.027 1.597.06v1.453h-.924c-1.363 0-1.93.675-1.93 1.912v1.78c0 .3.247.55.55.55h2.132l-.218 1.69H15.84c-.305 0-.55.24-.55.55v7.02c0 .33.293.59.623.54 5.135-.7 9.007-5.11 9.007-10.36C24.92 8.68 20.26 4 14.51 4"></path></svg></span></button></li><li class="u-textAlignCenter u-marginVertical10"><button class="button button--large button--dark button--chromeless is-touchIconFadeInPulse u-baseColor--buttonDark button--withIcon button--withSvgIcon button--bookmark js-bookmarkButton" title="Bookmark this story to read later" aria-label="Bookmark this story to read later" data-action="sign-up-prompt" data-sign-in-action="add-to-bookmarks" data-requires-token="true" data-redirect="https://medium.com/_/bookmark/p/6bdfeaece72a" data-action-source="post_share_widget-----6bdfeaece72a---------------------bookmark_sidebar"><span class="button-defaultState"><span class="svgIcon svgIcon--bookmark svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4zM21 23l-5.91-3.955-.148-.107a.751.751 0 0 0-.884 0l-.147.107L8 23V6.615C8 5.725 8.725 5 9.615 5h9.77C20.275 5 21 5.725 21 6.615V23z" fill-rule="evenodd"></path></svg></span></span><span class="button-activeState"><span class="svgIcon svgIcon--bookmarkFilled svgIcon--29px"><svg class="svgIcon-use" width="29" height="29" viewBox="0 0 29 29"><path d="M19.385 4h-9.77A2.623 2.623 0 0 0 7 6.615V23.01a1.022 1.022 0 0 0 1.595.847l5.905-4.004 5.905 4.004A1.022 1.022 0 0 0 22 23.011V6.62A2.625 2.625 0 0 0 19.385 4z" fill-rule="evenodd"></path></svg></span></span></button></li></ul></div></aside><div class="u-fixed u-bottom0 u-sizeFullWidth u-backgroundWhite u-boxShadowTop u-borderBox u-paddingTop10 u-paddingBottom10 u-zIndexMetabar u-xs-paddingLeft10 u-xs-paddingRight10 js-stickyFooter"><div class="u-maxWidth700 u-marginAuto u-flexCenter"><div class="u-fontSize16 u-flex1 u-flexCenter"><div class="u-flex0 u-inlineBlock u-paddingRight20 u-xs-paddingRight10"><a class="link u-baseColor--link avatar avatar--roundedRectangle" href="https://towardsdatascience.com/" title="Go to Towards Data Science" aria-label="Go to Towards Data Science" data-collection-slug="towards-data-science"><img src="Contextual%20Bandits%20and%20Reinforcement%20Learning%20%E2%80%93%20Towards%20Data%20Science_files/1F0LADxTtsKOgmPa-_7iUEQ_002.jpeg" class="avatar-image avatar-image--smaller" alt="Towards Data Science"></a></div><div class="u-flex1 u-inlineBlock"><div class="u-xs-hide">Never miss a story from<strong> Towards Data Science</strong>, when you sign up for Medium. <a class="link u-baseColor--link link--accent u-accentColor--textNormal u-accentColor--textDarken" href="https://medium.com/@Medium/personalize-your-medium-experience-with-users-publications-tags-26a41ab1ee0c#.hx4zuv3mg" data-action-source="sticky_footer">Learn more</a></div><div class="u-xs-show">Never miss a story from<strong> Towards Data Science</strong></div></div></div><div class="u-marginLeft50 u-xs-marginAuto"><button class="button button--primary button--dark is-active u-noUserSelect button--withChrome u-accentColor--buttonDark u-uiTextSemibold u-textUppercase u-fontSize12 button--followCollection js-followCollectionButton" data-action="sign-up-prompt" data-sign-in-action="toggle-subscribe-collection" data-requires-token="true" data-redirect="https://medium.com/_/subscribe/collection/towards-data-science" data-action-source="sticky_footer----7f60cf5620c9----------------------follow_metabar"><span class="button-label  button-defaultState js-buttonLabel">Get updates</span><span class="button-label button-activeState">Get updates</span></button></div></div></div><style class="js-collectionStyle">
.u-accentColor--borderLight {border-color: #668AAA !important;}
.u-accentColor--borderNormal {border-color: #668AAA !important;}
.u-accentColor--borderDark {border-color: #5A7690 !important;}
.u-accentColor--iconLight .svgIcon,.u-accentColor--iconLight.svgIcon {fill: #668AAA !important;}
.u-accentColor--iconNormal .svgIcon,.u-accentColor--iconNormal.svgIcon {fill: #668AAA !important;}
.u-accentColor--iconDark .svgIcon,.u-accentColor--iconDark.svgIcon {fill: #5A7690 !important;}
.u-accentColor--textNormal {color: #5A7690 !important;}
.u-accentColor--hoverTextNormal:hover {color: #5A7690 !important;}
.u-accentColor--textNormal.u-accentColor--textDarken:hover {color: #546C83 !important;}
.u-accentColor--textDark {color: #546C83 !important;}
.u-accentColor--backgroundLight {background-color: #668AAA !important;}
.u-accentColor--backgroundNormal {background-color: #668AAA !important;}
.u-accentColor--backgroundDark {background-color: #5A7690 !important;}
.u-accentColor--buttonDark {border-color: #5A7690 !important; color: #546C83 !important;}
.u-accentColor--buttonDark:hover {border-color: #546C83 !important;}
.u-accentColor--buttonDark .icon:before,.u-accentColor--buttonDark .svgIcon{color: #5A7690 !important; fill: #5A7690 !important;}
.u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: #668AAA !important; color: #5A7690 !important;}
.u-accentColor--buttonNormal:hover {border-color: #5A7690 !important;}
.u-accentColor--buttonNormal .icon:before,.u-accentColor--buttonNormal .svgIcon{color: #668AAA !important; fill: #668AAA !important;}
.u-accentColor--buttonNormal.button--filled .icon:before,.u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-accentColor--buttonDark.button--filled,.u-accentColor--buttonDark.button--withChrome.is-active,.u-accentColor--fillWhenActive.is-active {background-color: #5A7690 !important; border-color: #5A7690 !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: #668AAA !important; border-color: #668AAA !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.postArticle.is-withAccentColors .markup--user,.postArticle.is-withAccentColors .markup--query {color: #5A7690 !important;}.u-tintBgColor {background-color: rgba(53, 88, 118, 1) !important;}.u-tintBgColor .u-fadeLeft:before {background-image: linear-gradient(to right, rgba(53, 88, 118, 1) 0%, rgba(53, 88, 118, 0) 100%) !important;}.u-tintBgColor .u-fadeRight:after {background-image: linear-gradient(to right, rgba(53, 88, 118, 0) 0%, rgba(53, 88, 118, 1) 100%) !important;}
.u-tintSpectrum .u-baseColor--borderLight {border-color: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--borderNormal {border-color: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--borderDark {border-color: #E9F1FA !important;}
.u-tintSpectrum .u-baseColor--iconLight .svgIcon,.u-tintSpectrum .u-baseColor--iconLight.svgIcon {fill: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--iconNormal .svgIcon,.u-tintSpectrum .u-baseColor--iconNormal.svgIcon {fill: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--iconDark .svgIcon,.u-tintSpectrum .u-baseColor--iconDark.svgIcon {fill: #E9F1FA !important;}
.u-tintSpectrum .u-baseColor--textNormal {color: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--textDark {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--textDarker {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--backgroundLight {background-color: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--backgroundNormal {background-color: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--backgroundDark {background-color: #E9F1FA !important;}
.u-tintSpectrum .u-baseColor--buttonLight {border-color: #9FB3C6 !important; color: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--buttonLight:hover {border-color: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--buttonLight .icon:before,.u-tintSpectrum .u-baseColor--buttonLight .svgIcon {color: #9FB3C6 !important; fill: #9FB3C6 !important;}
.u-tintSpectrum .u-baseColor--buttonDark {border-color: #E9F1FA !important; color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--buttonDark:hover {border-color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--buttonDark .icon:before,.u-tintSpectrum .u-baseColor--buttonDark .svgIcon {color: #E9F1FA !important; fill: #E9F1FA !important;}
.u-tintSpectrum .u-baseColor--buttonNormal {border-color: #C5D2E1 !important; color: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--buttonNormal:hover {border-color: #E9F1FA !important;}
.u-tintSpectrum .u-baseColor--buttonNormal .icon:before,.u-tintSpectrum .u-baseColor--buttonNormal .svgIcon {color: #C5D2E1 !important; fill: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--buttonDark.button--filled,.u-tintSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: #E9F1FA !important; border-color: #E9F1FA !important; color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}
.u-tintSpectrum .u-baseColor--buttonNormal.button--filled,.u-tintSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: #C5D2E1 !important; border-color: #C5D2E1 !important; color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}
.u-tintSpectrum .u-baseColor--link {color: #C5D2E1 !important;}
.u-tintSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--link.link--darken:hover,.u-tintSpectrum .u-baseColor--link.link--darken:focus,.u-tintSpectrum .u-baseColor--link.link--darken:active {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--link.link--dark {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-tintSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-tintSpectrum .u-baseColor--link.link--dark.link--darken:active {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--link.link--darker {color: #FBFFFF !important;}
.u-tintSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: #9FB3C6;}
.u-tintSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: #9FB3C6;}
.u-tintSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: #9FB3C6;}
.u-tintSpectrum .svgIcon--logoNew path:nth-child(1) {stroke: none !important; fill: #637F99 !important;}
.u-tintSpectrum .svgIcon--logoNew path:nth-child(2) {stroke: none !important; fill: #7791A8 !important;}
.u-tintSpectrum .svgIcon--logoNew path:nth-child(3) {stroke: none !important; fill: #9FB3C6 !important;}
.u-tintSpectrum .svgIcon--logoNew path:nth-child(4) {stroke: none !important; fill: #C5D2E1 !important;}
.u-tintSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: #FBFFFF !important;}
.u-tintSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: #FBFFFF !important;}
.u-tintSpectrum  .ui-h1,.u-tintSpectrum  .ui-h2,.u-tintSpectrum  .ui-h3,.u-tintSpectrum  .ui-h4,.u-tintSpectrum  .ui-brand1,.u-tintSpectrum  .ui-brand2,.u-tintSpectrum  .ui-captionStrong {color: #FBFFFF !important; fill: #FBFFFF !important;}
.u-tintSpectrum  .ui-body,.u-tintSpectrum  .ui-caps {color: #FBFFFF !important; fill: #FBFFFF !important;}
.u-tintSpectrum  .ui-summary,.u-tintSpectrum  .ui-caption {color: #9FB3C6 !important; fill: #9FB3C6 !important;}
.u-tintSpectrum .u-accentColor--borderLight {border-color: #9FB3C6 !important;}
.u-tintSpectrum .u-accentColor--borderNormal {border-color: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--borderDark {border-color: #E9F1FA !important;}
.u-tintSpectrum .u-accentColor--iconLight .svgIcon,.u-tintSpectrum .u-accentColor--iconLight.svgIcon {fill: #9FB3C6 !important;}
.u-tintSpectrum .u-accentColor--iconNormal .svgIcon,.u-tintSpectrum .u-accentColor--iconNormal.svgIcon {fill: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--iconDark .svgIcon,.u-tintSpectrum .u-accentColor--iconDark.svgIcon {fill: #E9F1FA !important;}
.u-tintSpectrum .u-accentColor--textNormal {color: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--hoverTextNormal:hover {color: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: #FBFFFF !important;}
.u-tintSpectrum .u-accentColor--textDark {color: #FBFFFF !important;}
.u-tintSpectrum .u-accentColor--backgroundLight {background-color: #9FB3C6 !important;}
.u-tintSpectrum .u-accentColor--backgroundNormal {background-color: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--backgroundDark {background-color: #E9F1FA !important;}
.u-tintSpectrum .u-accentColor--buttonDark {border-color: #E9F1FA !important; color: #FBFFFF !important;}
.u-tintSpectrum .u-accentColor--buttonDark:hover {border-color: #FBFFFF !important;}
.u-tintSpectrum .u-accentColor--buttonDark .icon:before,.u-tintSpectrum .u-accentColor--buttonDark .svgIcon{color: #E9F1FA !important; fill: #E9F1FA !important;}
.u-tintSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: #C5D2E1 !important; color: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--buttonNormal:hover {border-color: #E9F1FA !important;}
.u-tintSpectrum .u-accentColor--buttonNormal .icon:before,.u-tintSpectrum .u-accentColor--buttonNormal .svgIcon{color: #C5D2E1 !important; fill: #C5D2E1 !important;}
.u-tintSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-tintSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}
.u-tintSpectrum .u-accentColor--buttonDark.button--filled,.u-tintSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-tintSpectrum .u-accentColor--fillWhenActive.is-active {background-color: #E9F1FA !important; border-color: #E9F1FA !important; color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}
.u-tintSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-tintSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: #C5D2E1 !important; border-color: #C5D2E1 !important; color: rgba(53, 88, 118, 1) !important; fill: rgba(53, 88, 118, 1) !important;}
.u-tintSpectrum .postArticle.is-withAccentColors .markup--user,.u-tintSpectrum .postArticle.is-withAccentColors .markup--query {color: #C5D2E1 !important;}
.u-accentColor--highlightFaint {background-color: rgba(233, 242, 253, 1) !important;}
.u-accentColor--highlightStrong.is-active .svgIcon {fill: rgba(200, 228, 255, 1) !important;}
.postArticle.is-withAccentColors .markup--quote.is-other {background-color: rgba(233, 242, 253, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-other {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(233, 242, 253, 1), rgba(233, 242, 253, 1));}
.postArticle.is-withAccentColors .markup--quote.is-me {background-color: rgba(215, 235, 254, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-me {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(215, 235, 254, 1), rgba(215, 235, 254, 1));}
.postArticle.is-withAccentColors .markup--quote.is-targeted {background-color: rgba(200, 228, 255, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-targeted {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(200, 228, 255, 1), rgba(200, 228, 255, 1));}
.postArticle.is-withAccentColors .markup--quote.is-selected {background-color: rgba(200, 228, 255, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--quote.is-selected {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(200, 228, 255, 1), rgba(200, 228, 255, 1));}
.postArticle.is-withAccentColors .markup--highlight {background-color: rgba(200, 228, 255, 1) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .markup--highlight {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(200, 228, 255, 1), rgba(200, 228, 255, 1));}.u-baseColor--iconNormal.avatar-halo {fill: rgba(0, 0, 0, 0.4980392156862745) !important;}</style><style class="js-collectionStyleConstant">.u-imageBgColor {background-color: rgba(0, 0, 0, 0.24705882352941178);}
.u-imageSpectrum .u-baseColor--borderLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .u-baseColor--borderNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-baseColor--borderDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--iconLight .svgIcon,.u-imageSpectrum .u-baseColor--iconLight.svgIcon {fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-baseColor--iconNormal .svgIcon,.u-imageSpectrum .u-baseColor--iconNormal.svgIcon {fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--iconDark .svgIcon,.u-imageSpectrum .u-baseColor--iconDark.svgIcon {fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--textNormal {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--textDark {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--textDarker {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--backgroundLight {background-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-baseColor--backgroundNormal {background-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--backgroundDark {background-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important; color: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-baseColor--buttonLight:hover {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .u-baseColor--buttonLight .icon:before,.u-imageSpectrum .u-baseColor--buttonLight .svgIcon {color: rgba(255, 255, 255, 0.8) !important; fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-baseColor--buttonDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonDark:hover {border-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonDark .icon:before,.u-imageSpectrum .u-baseColor--buttonDark .svgIcon {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important; color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal:hover {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal .icon:before,.u-imageSpectrum .u-baseColor--buttonNormal .svgIcon {color: rgba(255, 255, 255, 0.9490196078431372) !important; fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--buttonDark.button--filled,.u-imageSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: rgba(255, 255, 255, 1) !important; border-color: rgba(255, 255, 255, 1) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-baseColor--buttonNormal.button--filled,.u-imageSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: rgba(255, 255, 255, 0.9490196078431372) !important; border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-baseColor--link {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--darken:hover,.u-imageSpectrum .u-baseColor--link.link--darken:focus,.u-imageSpectrum .u-baseColor--link.link--darken:active {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--dark {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-imageSpectrum .u-baseColor--link.link--dark.link--darken:active {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--link.link--darker {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: rgba(255, 255, 255, 0.8);}
.u-imageSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: rgba(255, 255, 255, 0.8);}
.u-imageSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: rgba(255, 255, 255, 0.8);}
.u-imageSpectrum .svgIcon--logoNew path:nth-child(1) {stroke: none !important; fill: rgba(255, 255, 255, 0.4) !important;}
.u-imageSpectrum .svgIcon--logoNew path:nth-child(2) {stroke: none !important; fill: rgba(255, 255, 255, 0.4980392156862745) !important;}
.u-imageSpectrum .svgIcon--logoNew path:nth-child(3) {stroke: none !important; fill: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .svgIcon--logoNew path:nth-child(4) {stroke: none !important; fill: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum  .ui-h1,.u-imageSpectrum  .ui-h2,.u-imageSpectrum  .ui-h3,.u-imageSpectrum  .ui-h4,.u-imageSpectrum  .ui-brand1,.u-imageSpectrum  .ui-brand2,.u-imageSpectrum  .ui-captionStrong {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum  .ui-body,.u-imageSpectrum  .ui-caps {color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum  .ui-summary,.u-imageSpectrum  .ui-caption {color: rgba(255, 255, 255, 0.8) !important; fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-accentColor--borderLight {border-color: rgba(255, 255, 255, 0.6980392156862745) !important;}
.u-imageSpectrum .u-accentColor--borderNormal {border-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-accentColor--borderDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--iconLight .svgIcon,.u-imageSpectrum .u-accentColor--iconLight.svgIcon {fill: rgba(255, 255, 255, 0.8) !important;}
.u-imageSpectrum .u-accentColor--iconNormal .svgIcon,.u-imageSpectrum .u-accentColor--iconNormal.svgIcon {fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--iconDark .svgIcon,.u-imageSpectrum .u-accentColor--iconDark.svgIcon {fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--textNormal {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--hoverTextNormal:hover {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--textDark {color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--backgroundLight {background-color: rgba(255, 255, 255, 0.8980392156862745) !important;}
.u-imageSpectrum .u-accentColor--backgroundNormal {background-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--backgroundDark {background-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonDark {border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonDark:hover {border-color: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonDark .icon:before,.u-imageSpectrum .u-accentColor--buttonDark .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: rgba(255, 255, 255, 0.8980392156862745) !important; color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal:hover {border-color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal .icon:before,.u-imageSpectrum .u-accentColor--buttonNormal .svgIcon{color: rgba(255, 255, 255, 0.9490196078431372) !important; fill: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-imageSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-accentColor--buttonDark.button--filled,.u-imageSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-imageSpectrum .u-accentColor--fillWhenActive.is-active {background-color: rgba(255, 255, 255, 1) !important; border-color: rgba(255, 255, 255, 1) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-imageSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: rgba(255, 255, 255, 0.9490196078431372) !important; border-color: rgba(255, 255, 255, 0.9490196078431372) !important; color: rgba(0, 0, 0, 0.24705882352941178) !important; fill: rgba(0, 0, 0, 0.24705882352941178) !important;}
.u-imageSpectrum .postArticle.is-withAccentColors .markup--user,.u-imageSpectrum .postArticle.is-withAccentColors .markup--query {color: rgba(255, 255, 255, 0.9490196078431372) !important;}
.u-imageSpectrum .u-accentColor--highlightFaint {background-color: rgba(255, 255, 255, 0.2) !important;}
.u-imageSpectrum .u-accentColor--highlightStrong.is-active .svgIcon {fill: rgba(255, 255, 255, 0.6) !important;}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-other {background-color: rgba(255, 255, 255, 0.2) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-other {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.2), rgba(255, 255, 255, 0.2));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-me {background-color: rgba(255, 255, 255, 0.4) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-me {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.4), rgba(255, 255, 255, 0.4));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-targeted {background-color: rgba(255, 255, 255, 0.6) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-targeted {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-selected {background-color: rgba(255, 255, 255, 0.6) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--quote.is-selected {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}
.postArticle.is-withAccentColors .u-imageSpectrum .markup--highlight {background-color: rgba(255, 255, 255, 0.6) !important;}
body.is-withMagicUnderlines .postArticle.is-withAccentColors .u-imageSpectrum .markup--highlight {background-color: transparent !important; background-image: linear-gradient(to bottom, rgba(255, 255, 255, 0.6), rgba(255, 255, 255, 0.6));}.u-resetSpectrum .u-tintBgColor {background-color: rgba(255, 255, 255, 1) !important;}.u-resetSpectrum .u-tintBgColor .u-fadeLeft:before {background-image: linear-gradient(to right, rgba(255, 255, 255, 1) 0%, rgba(255, 255, 255, 0) 100%) !important;}.u-resetSpectrum .u-tintBgColor .u-fadeRight:after {background-image: linear-gradient(to right, rgba(255, 255, 255, 0) 0%, rgba(255, 255, 255, 1) 100%) !important;}
.u-resetSpectrum .u-baseColor--borderLight {border-color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--borderNormal {border-color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--borderDark {border-color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--iconLight .svgIcon,.u-resetSpectrum .u-baseColor--iconLight.svgIcon {fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--iconNormal .svgIcon,.u-resetSpectrum .u-baseColor--iconNormal.svgIcon {fill: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--iconDark .svgIcon,.u-resetSpectrum .u-baseColor--iconDark.svgIcon {fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--textNormal {color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--textNormal.u-baseColor--textDarken:hover {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--textDark {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--textDarker {color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--backgroundLight {background-color: rgba(0, 0, 0, 0.09803921568627451) !important;}
.u-resetSpectrum .u-baseColor--backgroundNormal {background-color: rgba(0, 0, 0, 0.2) !important;}
.u-resetSpectrum .u-baseColor--backgroundDark {background-color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonLight {border-color: rgba(0, 0, 0, 0.2980392156862745) !important; color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonLight:hover {border-color: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonLight .icon:before,.u-resetSpectrum .u-baseColor--buttonLight .svgIcon {color: rgba(0, 0, 0, 0.2980392156862745) !important; fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonDark {border-color: rgba(0, 0, 0, 0.6) !important; color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--buttonDark:hover {border-color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--buttonDark .icon:before,.u-resetSpectrum .u-baseColor--buttonDark .svgIcon {color: rgba(0, 0, 0, 0.6) !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal {border-color: rgba(0, 0, 0, 0.4980392156862745) !important; color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal:hover {border-color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal .icon:before,.u-resetSpectrum .u-baseColor--buttonNormal .svgIcon {color: rgba(0, 0, 0, 0.4980392156862745) !important; fill: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--buttonDark.button--filled,.u-resetSpectrum .u-baseColor--buttonDark.button--withChrome.is-active {background-color: rgba(0, 0, 0, 0.2980392156862745) !important; border-color: rgba(0, 0, 0, 0.2980392156862745) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-baseColor--buttonNormal.button--filled,.u-resetSpectrum .u-baseColor--buttonNormal.button--withChrome.is-active {background-color: rgba(0, 0, 0, 0.2) !important; border-color: rgba(0, 0, 0, 0.2) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-baseColor--link {color: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .u-baseColor--link.link--darkenOnHover:hover {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--link.link--darken:hover,.u-resetSpectrum .u-baseColor--link.link--darken:focus,.u-resetSpectrum .u-baseColor--link.link--darken:active {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--link.link--dark {color: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:hover,.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:focus,.u-resetSpectrum .u-baseColor--link.link--dark.link--darken:active {color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--link.link--darker {color: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum .u-baseColor--placeholderNormal ::-webkit-input-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}
.u-resetSpectrum .u-baseColor--placeholderNormal ::-moz-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}
.u-resetSpectrum .u-baseColor--placeholderNormal :-ms-input-placeholder {color: rgba(0, 0, 0, 0.2980392156862745);}
.u-resetSpectrum .svgIcon--logoNew path:nth-child(1) {stroke: none !important; fill: rgba(0, 0, 0, 0.2) !important;}
.u-resetSpectrum .svgIcon--logoNew path:nth-child(2) {stroke: none !important; fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .svgIcon--logoNew path:nth-child(3) {stroke: none !important; fill: rgba(0, 0, 0, 0.4) !important;}
.u-resetSpectrum .svgIcon--logoNew path:nth-child(4) {stroke: none !important; fill: rgba(0, 0, 0, 0.4980392156862745) !important;}
.u-resetSpectrum .svgIcon--logoWordmark {stroke: none !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum .svgIcon--logoMonogram {stroke: none !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum  .ui-h1,.u-resetSpectrum  .ui-h2,.u-resetSpectrum  .ui-h3,.u-resetSpectrum  .ui-h4,.u-resetSpectrum  .ui-brand1,.u-resetSpectrum  .ui-brand2,.u-resetSpectrum  .ui-captionStrong {color: rgba(0, 0, 0, 0.8) !important; fill: rgba(0, 0, 0, 0.8) !important;}
.u-resetSpectrum  .ui-body,.u-resetSpectrum  .ui-caps {color: rgba(0, 0, 0, 0.6) !important; fill: rgba(0, 0, 0, 0.6) !important;}
.u-resetSpectrum  .ui-summary,.u-resetSpectrum  .ui-caption {color: rgba(0, 0, 0, 0.2980392156862745) !important; fill: rgba(0, 0, 0, 0.2980392156862745) !important;}
.u-resetSpectrum .u-accentColor--borderLight {border-color: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--borderNormal {border-color: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--borderDark {border-color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--iconLight .svgIcon,.u-resetSpectrum .u-accentColor--iconLight.svgIcon {fill: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--iconNormal .svgIcon,.u-resetSpectrum .u-accentColor--iconNormal.svgIcon {fill: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--iconDark .svgIcon,.u-resetSpectrum .u-accentColor--iconDark.svgIcon {fill: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--textNormal {color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--hoverTextNormal:hover {color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--textNormal.u-accentColor--textDarken:hover {color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--textDark {color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--backgroundLight {background-color: rgba(2, 184, 117, 1) !important;}
.u-resetSpectrum .u-accentColor--backgroundNormal {background-color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--backgroundDark {background-color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark {border-color: rgba(0, 171, 107, 1) !important; color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark:hover {border-color: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark .icon:before,.u-resetSpectrum .u-accentColor--buttonDark .svgIcon{color: rgba(28, 153, 99, 1) !important; fill: rgba(28, 153, 99, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal:not(.clapButton--largePill) {border-color: rgba(2, 184, 117, 1) !important; color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal:hover {border-color: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal .icon:before,.u-resetSpectrum .u-accentColor--buttonNormal .svgIcon{color: rgba(0, 171, 107, 1) !important; fill: rgba(0, 171, 107, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal.button--filled .icon:before,.u-resetSpectrum .u-accentColor--buttonNormal.button--filled .svgIcon{color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonDark.button--filled,.u-resetSpectrum .u-accentColor--buttonDark.button--withChrome.is-active,.u-resetSpectrum .u-accentColor--fillWhenActive.is-active {background-color: rgba(28, 153, 99, 1) !important; border-color: rgba(28, 153, 99, 1) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .u-accentColor--buttonNormal.button--filled:not(.clapButton--largePill),.u-resetSpectrum .u-accentColor--buttonNormal.button--withChrome.is-active:not(.clapButton--largePill) {background-color: rgba(0, 171, 107, 1) !important; border-color: rgba(0, 171, 107, 1) !important; color: rgba(255, 255, 255, 1) !important; fill: rgba(255, 255, 255, 1) !important;}
.u-resetSpectrum .postArticle.is-withAccentColors .markup--user,.u-resetSpectrum .postArticle.is-withAccentColors .markup--query {color: rgba(0, 171, 107, 1) !important;}</style><div class="highlightMenu" data-action-scope="_actionscope_3" style="left: 436px; top: 4750px;"><div class="highlightMenu-inner"><div class="buttonSet"><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu u-accentColor--highlightStrong js-highlightMenuQuoteButton" data-action="sign-up-prompt" data-sign-in-action="quote" data-requires-token="true" data-redirect="https://towardsdatascience.com/contextual-bandits-and-reinforcement-learning-6bdfeaece72a" data-skip-onboarding="true" data-redirect-type="quote" data-action-source="quote_menu--------------------------highlight_text"><span class="svgIcon svgIcon--highlighter svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M13.7 15.964l5.204-9.387-4.726-2.62-5.204 9.387 4.726 2.62zm-.493.885l-1.313 2.37-1.252.54-.702 1.263-3.796-.865 1.228-2.213-.202-1.35 1.314-2.37 4.722 2.616z" fill-rule="evenodd"></path></svg></span></button><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu" data-action="sign-up-prompt" data-sign-in-action="quote-respond" data-redirect="https://towardsdatascience.com/contextual-bandits-and-reinforcement-learning-6bdfeaece72a" data-skip-onboarding="true" data-action-source="quote_menu--------------------------respond_text"><span class="svgIcon svgIcon--responseFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M19.074 21.117c-1.244 0-2.432-.37-3.532-1.096a7.792 7.792 0 0 1-.703-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.662 0 8.457 3.5 8.457 7.803 0 2.058-.85 3.984-2.403 5.448.023.17.06.35.118.55.192.69.537 1.38 1.026 2.04.15.21.172.48.058.7a.686.686 0 0 1-.613.38h-.03z" fill-rule="evenodd"></path></svg></span></button><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu" data-action="twitter" data-action-source="quote_menu" data-skip-onboarding="true"><span class="svgIcon svgIcon--twitterFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><path d="M21.725 5.338c-.744.47-1.605.804-2.513 1.006a3.978 3.978 0 0 0-2.942-1.293c-2.22 0-4.02 1.81-4.02 4.02 0 .32.034.63.07.94-3.31-.18-6.27-1.78-8.255-4.23a4.544 4.544 0 0 0-.574 2.01c.04 1.43.74 2.66 1.8 3.38-.63-.01-1.25-.19-1.79-.5v.08c0 1.93 1.38 3.56 3.23 3.95-.34.07-.7.12-1.07.14-.25-.02-.5-.04-.72-.07.49 1.58 1.97 2.74 3.74 2.8a8.49 8.49 0 0 1-5.02 1.72c-.3-.03-.62-.04-.93-.07A11.447 11.447 0 0 0 8.88 21c7.386 0 11.43-6.13 11.414-11.414.015-.21.01-.38 0-.578a7.604 7.604 0 0 0 2.01-2.08 7.27 7.27 0 0 1-2.297.645 3.856 3.856 0 0 0 1.72-2.23"></path></svg></span></button><div class="buttonSet-separator"></div><button class="button button--chromeless u-baseColor--buttonNormal button--withIcon button--withSvgIcon button--highlightMenu" data-action="sign-up-prompt" data-sign-in-action="highlight" data-redirect="https://towardsdatascience.com/contextual-bandits-and-reinforcement-learning-6bdfeaece72a" data-skip-onboarding="true" data-action-source="quote_menu--------------------------privatenote_text"><span class="svgIcon svgIcon--privatenoteFilled svgIcon--25px"><svg class="svgIcon-use" width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M17.662 4.552H7.346A4.36 4.36 0 0 0 3 8.898v5.685c0 2.168 1.614 3.962 3.697 4.28v2.77c0 .303.35.476.59.29l3.904-2.994h6.48c2.39 0 4.35-1.96 4.35-4.35V8.9c0-2.39-1.95-4.346-4.34-4.346zM16 14.31a.99.99 0 0 1-1.003.99h-4.994C9.45 15.3 9 14.85 9 14.31v-3.02a.99.99 0 0 1 1-.99v-.782a2.5 2.5 0 0 1 2.5-2.51c1.38 0 2.5 1.13 2.5 2.51v.782c.552.002 1 .452 1 .99v3.02z"></path><path d="M14 9.81c0-.832-.674-1.68-1.5-1.68-.833 0-1.5.84-1.5 1.68v.49h3v-.49z"></path></g></svg></span></button></div></div><div class="highlightMenu-arrowClip"><span class="highlightMenu-arrow"></span></div></div></div></div></div><div class="loadingBar"></div><script>// <![CDATA[
window["obvInit"] = function (opt_embedded) {window["obvInit"]["embedded"] = opt_embedded; window["obvInit"]["ready"] = true;}
// ]]></script><script>// <![CDATA[
var GLOBALS = {"audioUrl":"https://d1fcbxp97j4nb2.cloudfront.net","baseUrl":"https://towardsdatascience.com","buildLabel":"33501-c75a731","currentUser":{"userId":"lo_sL5hrCPWk201","isVerified":false,"subscriberEmail":"","hasPastMemberships":false,"isEnrolledInHightower":false,"isEligibleForHightower":false,"hightowerLastLockedAt":0},"currentUserHasUnverifiedEmail":false,"isAuthenticated":false,"isCurrentUserVerified":false,"language":"en-us","mediumTwitterScreenName":"medium","miroUrl":"https://cdn-images-1.medium.com","moduleUrls":{"base":"https://cdn-static-1.medium.com/_/fp/gen-js/main-base.bundle.s6bOpRU41OIUJxYZktHpkA.js","common-async":"https://cdn-static-1.medium.com/_/fp/gen-js/main-common-async.bundle.2qNri8g1ppyOm24W23jlZw.js","hightower":"https://cdn-static-1.medium.com/_/fp/gen-js/main-hightower.bundle.DsGj0ZOCAigrj4D6iLusWQ.js","home-screens":"https://cdn-static-1.medium.com/_/fp/gen-js/main-home-screens.bundle._VFsP4irb4sf-k-Q-gtnYg.js","misc-screens":"https://cdn-static-1.medium.com/_/fp/gen-js/main-misc-screens.bundle.nZuw2VEQ6GqLU15iRUX9Lw.js","notes":"https://cdn-static-1.medium.com/_/fp/gen-js/main-notes.bundle.BEwdf2YsKKVXpf2VkgSv7Q.js","payments":"https://cdn-static-1.medium.com/_/fp/gen-js/main-payments.bundle.ZSrlB3mXBfJrEdrLgld8XA.js","posters":"https://cdn-static-1.medium.com/_/fp/gen-js/main-posters.bundle.SWwFDovfr-SuNmeCKkiWsA.js","power-readers":"https://cdn-static-1.medium.com/_/fp/gen-js/main-power-readers.bundle.yj11FfhEUbAmFOIo-w7sWg.js","pubs":"https://cdn-static-1.medium.com/_/fp/gen-js/main-pubs.bundle._3CRksookS2EGyl1IYANTw.js","stats":"https://cdn-static-1.medium.com/_/fp/gen-js/main-stats.bundle.efyOpWCjxF-GS-_fHj2cGw.js"},"previewConfig":{"weightThreshold":1,"weightImageParagraph":0.51,"weightIframeParagraph":0.8,"weightTextParagraph":0.08,"weightEmptyParagraph":0,"weightP":0.003,"weightH":0.005,"weightBq":0.003,"minPTextLength":60,"truncateBoundaryChars":20,"detectTitle":true,"detectTitleLevThreshold":0.15},"productName":"Medium","supportsEdit":true,"termsUrl":"//medium.com/policy/9db0094a1e0f","textshotHost":"textshot.medium.com","transactionId":"1524663452536:bd95b2e77f8e","useragent":{"browser":"firefox","family":"firefox","os":"","version":59,"supportsDesktopEdit":true,"supportsInteract":true,"supportsView":true,"isMobile":false,"isTablet":false,"isNative":false,"supportsFileAPI":true,"isTier1":true,"clientVersion":"","unknownParagraphsBad":false,"clientChannel":"","supportsRealScrollEvents":true,"supportsVhUnits":true,"ruinsViewportSections":false,"supportsHtml5Video":true,"supportsMagicUnderlines":true,"isWebView":false,"isFacebookWebView":false,"supportsProgressiveMedia":true,"supportsPromotedPosts":true,"isBot":false,"isNativeIphone":false,"supportsCssVariables":true,"supportsVideoSections":true,"emojiSupportLevel":1,"isSearchBot":false,"supportsScrollableMetabar":true},"variants":{"allow_access":true,"allow_signup":true,"allow_test_auth":"disallow","signin_services":"twitter,facebook,google,email,google-fastidv","signup_services":"twitter,facebook,google,email,google-fastidv","android_rating_prompt_recommend_threshold":5,"google_sign_in_android":true,"reengagement_notification_duration":3,"browsable_stream_config_bucket":"curated-topics","enable_series_creation":true,"enable_your_series_pages":true,"enable_productionized_series":true,"enable_dedicated_series_tab_api_ios":true,"enable_clap_milestone_notifications":true,"enable_series_stats_page":true,"enable_post_import":true,"enable_export_members":true,"enable_series_card_background_creation":true,"available_monthly_plan":"60e220181034","available_annual_plan":"2c754bcc2995","enable_sms":true,"is_not_medium_subscriber":true,"disable_followed_tag_fan_out":true,"enable_glyph":true,"glyph_font_set":"m2","enable_branding":true,"enable_branding_fonts":true,"enable_sequence_carousel":true,"enable_multirecommends":true,"enable_post_monger_v2":true,"enable_post_monger_v3":true,"enable_hightower_editor_copy_v2":true,"enable_user_post_metering":true,"max_premium_content_per_user_under_metering":3,"tag_intercom_user_on_metering_count":3,"enable_topic_writer_onboarding":true,"enable_strong_graph_chp_reorder":true,"enable_unsplash_images":true,"enable_top_stories_for_you":true,"enable_ios_member_post_labeling":true,"enable_li_search_collection":true,"enable_homepage_remodel":true,"enable_signin_wall_custom_domain":true,"enable_standalone_profile_edit_page":true,"enable_standalone_user_follow_pages":true,"enable_post_footer_copy":true,"app_download_email_template":"control","enable_hack_series_web":true,"enable_email_sign_in_captcha":true,"enable_infinite_ranked_feed":true,"enable_topic_lifecycle_email":true,"enable_marketing_emails":true,"enable_ranked_feed_in_digest":true,"enable_more_top_posts_in_digest":true,"enable_curation_post_locking":true,"disable_ios_popchunk_ui":true,"disable_android_popchunk_ui":true,"enable_email_automation_system":true,"ios_hide_avatars_on_home":true,"raise_editors_picks_digest":"control","disable_ios_nfyn_carousel_ui":true,"disable_ios_popular_on_medium_carousel_ui":true,"disable_ios_reading_list_carousel_ui":true,"android_disable_author_avatars":true,"enable_evergreen_provider_homepage_li":true,"enable_persistent_user_id_for_dnt":true,"enable_evergreen_section_digest":true,"deprecate_old_sequences":true,"enable_truncated_rss_for_tags_and_topics":true,"enable_ios_related_reads_api_change":true,"enable_ios_related_reads_ui_carousel":true,"enable_ios_responses_collapsed":true},"xsrfToken":"","iosAppId":"828256236","supportEmail":"yourfriends@medium.com","fp":{"/icons/monogram-mask.svg":"https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg","/icons/favicon-dev-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-dev-editor.YKKRxBO8EMvIqhyCwIiJeQ.ico","/icons/favicon-hatch-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-hatch-editor.BuEyHIqlyh2s_XEk4Rl32Q.ico","/icons/favicon-medium-editor.ico":"https://cdn-static-1.medium.com/_/fp/icons/favicon-medium-editor.PiakrZWB7Yb80quUVQWM6g.ico"},"authBaseUrl":"https://medium.com","imageUploadSizeMb":25,"isAuthDomainRequest":false,"domainCollectionSlug":"towards-data-science","algoliaApiEndpoint":"https://MQ57UUUQZ2-dsn.algolia.net","algoliaAppId":"MQ57UUUQZ2","algoliaSearchOnlyApiKey":"394474ced050e3911ae2249ecc774921","iosAppStoreUrl":"https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&mt=8","iosAppLinkBaseUrl":"medium:","algoliaIndexPrefix":"medium_","androidPlayStoreUrl":"https://play.google.com/store/apps/details?id=com.medium.reader","googleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","androidPackage":"com.medium.reader","androidPlayStoreMarketScheme":"market://details?id=com.medium.reader","googleAuthUri":"https://accounts.google.com/o/oauth2/auth","androidScheme":"medium","layoutData":{"useDynamicScripts":false,"googleAnalyticsTrackingCode":"UA-24232453-2","jsShivUrl":"https://cdn-static-1.medium.com/_/fp/js/shiv.RI2ePTZ5gFmMgLzG5bEVAA.js","useDynamicCss":false,"faviconUrl":"https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico","faviconImageId":"1*8I-HPL0bfoIzGied-dzOvA.png","fontSets":[{"id":8,"url":"https://glyph.medium.com/css/e/sr/latin/e/ssr/latin/e/ssb/latin/m2.css"},{"id":9,"url":"https://glyph.medium.com/css/mkt.css"},{"id":10,"url":"https://glyph.medium.com/css/elv8.css"}],"editorFaviconUrl":"https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium-editor.3Y6xpZ-0FSdWDnPM3hSBIA.ico","glyphUrl":"https://glyph.medium.com"},"authBaseUrlRev":"moc.muidem//:sptth","isDnt":false,"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","archiveUploadSizeMb":100,"paymentData":{"currencies":{"1":{"label":"US Dollar","external":"usd"}},"countries":{"1":{"label":"United States of America","external":"US"}},"accountTypes":{"1":{"label":"Individual","external":"individual"},"2":{"label":"Company","external":"company"}}},"previewConfig2":{"weightThreshold":1,"weightImageParagraph":0.05,"raiseImage":true,"enforceHeaderHierarchy":true,"isImageInsetRight":true},"isAmp":false,"iosScheme":"medium","isSwBoot":false,"lightstep":{"accessToken":"ce5be895bef60919541332990ac9fef2","carrier":"{\"ot-tracer-spanid\":\"37433fdf70b218bc\",\"ot-tracer-traceid\":\"3a853a764f79b66d\",\"ot-tracer-sampled\":\"true\"}","host":"collector-medium.lightstep.com"},"facebook":{"key":"542599432471018","namespace":"medium-com","scope":{"default":["public_profile","email","user_friends"],"connect":["public_profile","email","user_friends"],"login":["public_profile","email","user_friends"],"share":["public_profile","email","user_friends","publish_actions"]}},"mailingListArchiveUploadSizeMb":2,"editorsPicksTopicId":"3985d2a191c5","popularOnMediumTopicId":"9d34e48ecf94","memberContentTopicId":"13d7efd82fb2","audioContentTopicId":"3792abbd134","brandedSequenceId":"7d337ddf1941","isDoNotAuth":false,"goldfinchUrl":"https://goldfinch.medium.com","buggle":{"url":"https://buggle.medium.com","videoUrl":"https://cdn-videos-1.medium.com","audioUrl":"https://cdn-audio-1.medium.com"},"referrerType":2,"isMeteredOut":false,"meterConfig":{"maxUnlockCount":3,"windowLength":"MONTHLY"},"partnerProgramEmail":"partnerprogram@medium.com","userResearchPrompts":[{"promptId":"lo_post_page_4","type":0,"url":"www.calendly.com"},{"promptId":"lo_home_page","type":1,"url":"www.calendly.com"},{"promptId":"lo_profile_page","type":2,"url":"www.calendly.com"}],"recaptchaKey":"6LdAokEUAAAAAC7seICd4vtC8chDb3jIXDQulyUJ","paypalClientMode":"production","signinWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"countryCode":"ES"}
// ]]></script><script charset="UTF-8" src="Contextual%20Bandits%20and%20Reinforcement%20Learning%20%E2%80%93%20Towards%20Data%20Science_files/main-base.js" async=""></script><script>// <![CDATA[
window["obvInit"]({"value":{"id":"6bdfeaece72a","versionId":"d0bf6cd430e0","creatorId":"d002f056f8c","creator":{"userId":"d002f056f8c","name":"Pavel Surmenok","username":"surmenok","createdAt":1443043369304,"lastPostCreatedAt":1522450062156,"imageId":"0*Er1PaJU1KWzERL6w.jpeg","backgroundImageId":"","bio":"Engineering Manager at JustAnswer. Machine learning engineering and chatbots. All opinions are my own.","twitterScreenName":"surmenok","socialStats":{"userId":"d002f056f8c","usersFollowedCount":347,"usersFollowedByCount":1638,"type":"SocialStats"},"social":{"userId":"lo_sL5hrCPWk201","targetUserId":"d002f056f8c","type":"Social"},"facebookAccountId":"970668082998286","allowNotes":1,"isNsfw":false,"type":"User"},"homeCollection":{"id":"7f60cf5620c9","name":"Towards Data Science","slug":"towards-data-science","tags":["DATA SCIENCE","MACHINE LEARNING","ARTIFICIAL INTELLIGENCE","BIG DATA","ANALYTICS"],"creatorId":"895063a310f4","description":"Sharing concepts, ideas, and codes.","shortDescription":"Sharing concepts, ideas, and codes.","image":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":71898,"activeAt":1524662731882},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"memberOfMembershipPlanId":"","isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"twitterUsername":"TDataScience","facebookPageName":"towardsdatascience","publicEmail":"publication@towardsdatascience.com","collectionMastheadId":"8b6aceffde6","domain":"towardsdatascience.com","sections":[{"type":2,"collectionHeaderMetadata":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5}},{"type":1,"postListMetadata":{"source":4,"layout":2,"number":1,"postIds":[],"tagSlug":"Towards Data Science"}},{"type":1,"postListMetadata":{"source":1,"layout":4,"number":6,"postIds":[],"sectionHeader":"Latest"}},{"type":3,"promoMetadata":{"sectionHeader":"","promoId":"39ecad7f281"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["e82cfba4d9c2","7a75effe7cc"],"sectionHeader":"Our Letters"}},{"type":3,"promoMetadata":{"sectionHeader":"","promoId":"dbabc89840b7"}},{"type":1,"postListMetadata":{"source":2,"layout":7,"number":7,"postIds":[],"sectionHeader":"Trending"}},{"type":3,"promoMetadata":{"sectionHeader":"","promoId":"69b26f0f1e35"}},{"type":1,"postListMetadata":{"source":4,"layout":4,"number":9,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Editors' Picks"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":3,"postIds":["16d776fd34bd","378cbd5e5c85","e7e681d4f03f"],"sectionHeader":"Companies That Support Us"}},{"type":3,"promoMetadata":{"sectionHeader":"","promoId":"8b04cd40f0c8"}},{"type":1,"postListMetadata":{"source":4,"layout":5,"number":3,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Last Chance To Read"}}],"tintColor":"#FF355876","lightText":true,"favicon":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF668AAA","point":0},{"color":"#FF61809D","point":0.1},{"color":"#FF5A7690","point":0.2},{"color":"#FF546C83","point":0.3},{"color":"#FF4D6275","point":0.4},{"color":"#FF455768","point":0.5},{"color":"#FF3D4C5A","point":0.6},{"color":"#FF34414C","point":0.7},{"color":"#FF2B353E","point":0.8},{"color":"#FF21282F","point":0.9},{"color":"#FF161B1F","point":1}],"backgroundColor":"#FFFFFFFF"},"tintBackgroundSpectrum":{"colorPoints":[{"color":"#FF355876","point":0},{"color":"#FF4D6C88","point":0.1},{"color":"#FF637F99","point":0.2},{"color":"#FF7791A8","point":0.3},{"color":"#FF8CA2B7","point":0.4},{"color":"#FF9FB3C6","point":0.5},{"color":"#FFB2C3D4","point":0.6},{"color":"#FFC5D2E1","point":0.7},{"color":"#FFD7E2EE","point":0.8},{"color":"#FFE9F1FA","point":0.9},{"color":"#FFFBFFFF","point":1}],"backgroundColor":"#FF355876"},"highlightSpectrum":{"colorPoints":[{"color":"#FFEDF4FC","point":0},{"color":"#FFE9F2FD","point":0.1},{"color":"#FFE6F1FD","point":0.2},{"color":"#FFE2EFFD","point":0.3},{"color":"#FFDFEEFD","point":0.4},{"color":"#FFDBECFE","point":0.5},{"color":"#FFD7EBFE","point":0.6},{"color":"#FFD4E9FE","point":0.7},{"color":"#FFD0E7FF","point":0.8},{"color":"#FFCCE6FF","point":0.9},{"color":"#FFC8E4FF","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[{"type":4,"title":"Data Science","url":"https://towardsdatascience.com/data-science/home","topicId":"cf416843aadc","source":"topicId"},{"type":4,"title":"Machine Learning","url":"https://towardsdatascience.com/machine-learning/home","topicId":"a5c9b2f1cb6b","source":"topicId"},{"type":4,"title":"Programming","url":"https://towardsdatascience.com/programming/home","topicId":"41533a1dc73c","source":"topicId"},{"type":4,"title":"Visualization","url":"https://towardsdatascience.com/data-visualization/home","topicId":"825e6cb8b9ce","source":"topicId"},{"type":4,"title":"Picks","url":"https://towardsdatascience.com/editors-picks/home","topicId":"e81f4fc5ee6b","source":"topicId"},{"type":4,"title":"Contribute","url":"https://towardsdatascience.com/contribute/home","topicId":"6ae0c8697d8c","source":"topicId"}],"colorBehavior":2,"instantArticlesState":0,"acceleratedMobilePagesState":0,"googleAnalyticsId":"UA-19707169-24","ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5},"paidForDomainAt":1509037374118,"type":"Collection"},"homeCollectionId":"7f60cf5620c9","title":"Contextual Bandits and Reinforcement Learning","detectedLanguage":"en","latestVersion":"d0bf6cd430e0","latestPublishedVersion":"d0bf6cd430e0","hasUnpublishedEdits":false,"latestRev":121,"createdAt":1503795391417,"updatedAt":1524193732087,"acceptedAt":0,"firstPublishedAt":1503796642072,"latestPublishedAt":1508293724332,"vote":false,"experimentalCss":"","displayAuthor":"","content":{"subtitle":"If you develop personalization of user experience for your website or an app, contextual bandits can help you. Using contextual bandits…","bodyModel":{"paragraphs":[{"name":"4dc5","type":3,"text":"Contextual Bandits and Reinforcement Learning","markups":[]},{"name":"7090","type":4,"text":"Source: https://blog.iterable.com/why-you-should-become-a-multi-armed-bandit-1cb6651063f5","markups":[{"type":3,"start":8,"end":89,"href":"https://blog.iterable.com/why-you-should-become-a-multi-armed-bandit-1cb6651063f5","title":"","rel":"nofollow","anchorType":0}],"layout":1,"metadata":{"id":"1*FH4t-DcuKWfLYRWvd4JIjA.png","originalWidth":586,"originalHeight":465,"isFeatured":true}},{"name":"d2fa","type":1,"text":"If you develop personalization of user experience for your website or an app, contextual bandits can help you. Using contextual bandits, you can choose which content to display to the user, rank advertisements, optimize search results, select the best image to show on the page, and much more.","markups":[]},{"name":"121a","type":1,"text":"There are many names for this class of algorithms: contextual bandits, multi-world testing, associative bandits, learning with partial feedback, learning with bandit feedback, bandits with side information, multi-class classification with bandit feedback, associative reinforcement learning, one-step reinforcement learning.","markups":[]},{"name":"366c","type":1,"text":"Researchers approach the problem from two different angles. You can think about contextual bandits as an extension of multi-armed bandits, or as a simplified version of reinforcement learning.","markups":[]},{"name":"1660","type":1,"text":"“Bandit” in “multi-armed bandits” comes from “one-armed bandit” machines used in a casino. Imagine that you are in a casino with many one-armed bandit machines. Each machine has a different probability of a win. Your goal is to maximize total payout. You can pull a limited number of arms, and you don’t know which bandit to use to get the best payout. The problem involves exploration/exploitation tradeoff: you should balance between trying different bandits to learn more about an expected payout of every machine, but you also want to exploit the best bandit you know about more. This problem has many real-world applications, including website optimization, clinical trials, adaptive routing and financial portfolio design. You can think about it as smarter A/B testing.","markups":[]},{"name":"795e","type":1,"text":"The multi-armed bandit algorithm outputs an action but doesn’t use any information about the state of the environment (context). For example, if you use a multi-armed bandit to choose whether to display cat images or dog images to the user of your website, you’ll make the same random decision even if you know something about preferences of the user. The contextual bandit extends the model by making the decision conditional on the state of the environment.","markups":[]},{"name":"58be","type":4,"text":"Source: https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0","markups":[{"type":3,"start":8,"end":151,"href":"https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0","title":"","rel":"nofollow","anchorType":0}],"layout":1,"metadata":{"id":"1*HH9PGI9dThtu6BpJtLmABg.png","originalWidth":1788,"originalHeight":571}},{"name":"b372","type":1,"text":"With such model, you not only optimize decision based on previous observations, but you also personalize decisions for every situation. You will show an image of a cat to a cat person, and an image of a dog to a dog person, you may show different images at different times of the day and days of the week.","markups":[]},{"name":"6600","type":1,"text":"The algorithm observes a context, makes a decision, choosing one action from a number of alternative actions, and observes an outcome of that decision. An outcome defines a reward. The goal is to maximize average reward.","markups":[]},{"name":"3bc3","type":1,"text":"For example, you can use a contextual bandit to select which news article to show first on the main page of your website to optimize click through rate. The context is information about the user: where they come from, previously visited pages of the site, device information, geolocation, etc. An action is a choice of what news article to display. An outcome is whether the user clicked on a link or not. A reward is binary: 0 if there is no click, 1 if there is a click.","markups":[]},{"name":"6e63","type":1,"text":"If we would have reward values for every possible action for every example, we could just use any classification algorithm, using context data as features and action with the best reward as a label. The challenge is that we don’t know which action is the best, we have only partial information: reward value for the action which was used in the example. You still can use machine learning models for this, but you’ll have to change the cost function. A naïve implementation is to try to predict the reward.","markups":[]},{"name":"cf04","type":1,"text":"Microsoft published a whitepaper with an overview of the methodology and description of their implementation of a multi-world testing service. This service is being developed by Microsoft Research group in New York. Previously, many of the researchers in that group were working in that field at Yahoo. Microsoft Multi-world testing service uses Vowpal Wabbit, an open source library that implements online and offline training algorithms for contextual bandits. Offline training and evaluation algorithms is described in the paper “Doubly Robust Policy Evaluation and Learning” (Miroslav Dudik, John Langford, Lihong Li).","markups":[{"type":3,"start":0,"end":32,"href":"https://github.com/Microsoft/mwt-ds/raw/master/images/MWT-WhitePaper.pdf","title":"","rel":"","anchorType":0},{"type":3,"start":533,"end":577,"href":"https://arxiv.org/pdf/1103.4601.pdf","title":"","rel":"","anchorType":0}]},{"name":"9d2e","type":6,"text":"“Two kinds of approaches address offline learning in contextual bandits. The first, which we call the direct method (DM), estimates the reward function from given data and uses this estimate in place of actual reward to evaluate the policy value on a set of contexts. The second kind, called inverse propensity score (IPS) (Horvitz & Thompson, 1952), uses importance weighting to correct for the incorrect proportions of actions in the historic data. The first approach requires an accurate model of rewards, whereas the second approach requires an accurate model of the past policy. In general, it might be difficult to accurately model rewards, so the first assumption can be too restrictive. On the other hand, it is usually possible to model the past policy quite well. However, the second kind of approach often suffers from large variance especially when the past policy differs significantly from the policy being evaluated.","markups":[]},{"name":"cd5a","type":6,"text":"In this paper, we propose to use the technique of doubly robust (DR) estimation to overcome problems with the two existing approaches. Doubly robust (or doubly protected) estimation (Cassel et al., 1976; Robins et al., 1994; Robins & Rotnitzky, 1995; Lunceford & Davidian, 2004; Kang & Schafer, 2007) is a statistical approach for estimation from incomplete data with an important property: if either one of the two estimators (in DM and IPS) is correct, then the estimation is unbiased. This method thus increases the chances of drawing reliable inference. “","markups":[]},{"name":"ce83","type":1,"text":"A couple of video tutorials on contextual bandits:","markups":[]},{"name":"c1b1","type":1,"text":"ICML and KDD 2010 Tutorial on Learning through Exploration","markups":[{"type":3,"start":0,"end":58,"href":"http://hunch.net/~exploration_learning/","title":"","rel":"","anchorType":0}]},{"name":"13d5","type":1,"text":"SIGIR 2016 Tutorial on Counterfactual Evaluation and Learning for Search, Recommendation and Ad Placement","markups":[{"type":3,"start":0,"end":105,"href":"http://www.cs.cornell.edu/~adith/CfactSIGIR2016/","title":"","rel":"","anchorType":0}]},{"name":"e03b","type":1,"text":"Learning through Exploration","markups":[{"type":3,"start":0,"end":28,"href":"http://videolectures.net/kdd2010_beygelzimer_langford_lte/","title":"","rel":"","anchorType":0}]},{"name":"bec6","type":1,"text":"And you can find a lot of links to other resources here.","markups":[{"type":3,"start":51,"end":55,"href":"https://livingthing.danmackinlay.name/bandit_problems.html","title":"","rel":"","anchorType":0}]},{"name":"e397","type":1,"text":"You can think about reinforcement learning as an extension of contextual bandits.","markups":[]},{"name":"261c","type":4,"text":"Source: https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0","markups":[{"type":3,"start":8,"end":151,"href":"https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0","title":"","rel":"nofollow","anchorType":0}],"layout":1,"metadata":{"id":"1*TcA7ske9sdMcXuXTn68-9A.png","originalWidth":1761,"originalHeight":741}},{"name":"149a","type":1,"text":"You still have an agent (policy) that takes actions based on the state of the environment, observes a reward. The difference is that the agent can take multiple consecutive actions, and reward information is sparse. For example, you can train a model to play chess. The model will use the state of the chess board as context, will decide on which moves to make, but it will get a reward only at the very end of the game: win, loss, or draw. The sparsity of reward information makes it harder to train the model. You encounter a problem of credit assignment problem: how to assign credit or blame individual actions.","markups":[]},{"name":"9850","type":1,"text":"There are many variations of reinforcement learning algorithms. One of the extensions of reinforcement learning is deep reinforcement learning. It uses a deep neural network as a part of the system.","markups":[]},{"name":"50bb","type":1,"text":"Arthur Juliani wrote a nice tutorial on reinforcement learning with Tensorflow.","markups":[{"type":3,"start":28,"end":78,"href":"https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0","title":"","rel":"","anchorType":0}]},{"name":"9e1b","type":1,"text":"Researchers interested in contextual bandits seem to focus more on creating algorithms that have better statistical qualities, for example, regret guarantees. Regret is an expected difference between an expectation of the sum of rewards when using an optimal policy and the sum of collected rewards using the contextual bandit policy learned from data. Some classes of algorithms have theoretical guarantees on upper bound of regret.","markups":[]},{"name":"959f","type":1,"text":"Researchers interested in reinforcement learning seem to be more interested in applying machine learning algorithms to new problems: robotics, self-driving cars, inventory management, trading systems. They often focus on the development of algorithms that can improve state of the art for some set of problems.","markups":[]},{"name":"2f47","type":1,"text":"Technical approaches are also different. Microsoft Multiworld Testing Whitepaper describes training algorithm that uses a negative IPS (inverse propensity score) as a loss function. Minimizing the loss function will lead to maximization of IPS estimator. I couldn’t find anybody using IPS estimator in reinforcement learning algorithms. If you get reinforcement learning algorithm with policy gradients and simplify it to a contextual bandit by reducing a number of steps to one, the model will be very similar to a supervised classification model. For the loss function, you will use cross-entropy but multiply by the reward value.","markups":[]},{"name":"ec8b","type":1,"text":"It was interesting to compare two different classes of algorithms which converge in a narrow area of the contextual bandits. I could miss something as I haven’t dig deep into theoretical foundations yet. Please let me know if you notice any mistakes of missing details in this article.","markups":[]},{"name":"9c73","type":1,"text":"See also:","markups":[]},{"name":"1344","type":1,"text":"Best Sources of Deep Learning News","markups":[{"type":3,"start":0,"end":34,"href":"https://medium.com/@surmenok/best-sources-of-deep-learning-news-fbc98815bad3","title":"","rel":"","anchorType":0}]},{"name":"869d","type":1,"text":"Jeff Dean’s Talk on Large-Scale Deep Learning","markups":[{"type":3,"start":0,"end":45,"href":"https://becominghuman.ai/jeff-deans-talk-on-large-scale-deep-learning-171fb8c8ac57","title":"","rel":"","anchorType":0}]},{"name":"948f","type":1,"text":"Character-level Convolutional Networks for Text Classification","markups":[{"type":3,"start":0,"end":62,"href":"https://medium.com/@surmenok/character-level-convolutional-networks-for-text-classification-d582c0c36ace","title":"","rel":"","anchorType":0}]},{"name":"2c61","type":1,"text":"The article was originally published on http://pavel.surmenok.com/2017/08/26/contextual-bandits-and-reinforcement-learning/","markups":[{"type":3,"start":40,"end":123,"href":"http://pavel.surmenok.com/2017/08/26/contextual-bandits-and-reinforcement-learning/","title":"","rel":"nofollow noopener","anchorType":0},{"type":2,"start":0,"end":123}]}],"sections":[{"name":"3a6b","startIndex":0},{"name":"160a","startIndex":5},{"name":"b062","startIndex":12},{"name":"64ef","startIndex":20},{"name":"84b4","startIndex":25},{"name":"fd2e","startIndex":27},{"name":"e395","startIndex":28},{"name":"d4a8","startIndex":29},{"name":"e798","startIndex":33}]},"postDisplay":{"coverless":true}},"virtuals":{"statusForCollection":"APPROVED","allowNotes":true,"previewImage":{"imageId":"1*FH4t-DcuKWfLYRWvd4JIjA.png","filter":"","backgroundSize":"","originalWidth":586,"originalHeight":465,"strategy":"resample","height":0,"width":0},"wordCount":1429,"imageCount":3,"readingTime":5.942452830188679,"subtitle":"If you develop personalization of user experience for your website or an app, contextual bandits can help you. Using contextual bandits…","publishedInCount":1,"usersBySocialRecommends":[],"recommends":60,"socialRecommends":[],"isBookmarked":false,"tags":[{"slug":"machine-learning","name":"Machine Learning","postCount":33374,"virtuals":{"isFollowing":false},"metadata":{"followerCount":23750,"postCount":33374,"coverImage":{"id":"1*YryHJzKJy0ZYOWjlS2shMQ.jpeg","originalWidth":4102,"originalHeight":2560}},"type":"Tag"},{"slug":"artificial-intelligence","name":"Artificial Intelligence","postCount":47340,"virtuals":{"isFollowing":false},"metadata":{"followerCount":673793,"postCount":47340,"coverImage":{"id":"1*gAn_BSffVBcwCIR6bDgK1g.jpeg"}},"type":"Tag"},{"slug":"deep-learning","name":"Deep Learning","postCount":7803,"virtuals":{"isFollowing":false},"metadata":{"followerCount":9996,"postCount":7803,"coverImage":{"id":"1*Fr-q6mQNYjJr6hTglTic7g.jpeg","originalWidth":5184,"originalHeight":3456}},"type":"Tag"},{"slug":"ai","name":"AI","postCount":15607,"virtuals":{"isFollowing":false},"metadata":{"followerCount":3887,"postCount":15607,"coverImage":{"id":"1*QATCo0QEJYiDzVAkvy_dDA.png","originalWidth":1958,"originalHeight":827,"isFeatured":true}},"type":"Tag"},{"slug":"data-science","name":"Data Science","postCount":22043,"virtuals":{"isFollowing":false},"metadata":{"followerCount":14315,"postCount":22043,"coverImage":{"id":"1*YryHJzKJy0ZYOWjlS2shMQ.jpeg","originalWidth":4102,"originalHeight":2560}},"type":"Tag"}],"socialRecommendsCount":0,"responsesCreatedCount":0,"links":{"entries":[{"url":"https://medium.com/@surmenok/best-sources-of-deep-learning-news-fbc98815bad3","alts":[{"type":2,"url":"medium://p/fbc98815bad3"},{"type":3,"url":"medium://p/fbc98815bad3"}],"httpStatus":200},{"url":"https://medium.com/@surmenok/character-level-convolutional-networks-for-text-classification-d582c0c36ace","alts":[{"type":2,"url":"medium://p/d582c0c36ace"},{"type":3,"url":"medium://p/d582c0c36ace"}],"httpStatus":200},{"url":"http://www.cs.cornell.edu/~adith/CfactSIGIR2016/","alts":[],"httpStatus":200},{"url":"https://livingthing.danmackinlay.name/bandit_problems.html","alts":[],"httpStatus":200},{"url":"https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0","alts":[{"type":3,"url":"medium://p/d195264329d0"},{"type":2,"url":"medium://p/d195264329d0"}],"httpStatus":200},{"url":"http://hunch.net/~exploration_learning/","alts":[],"httpStatus":200},{"url":"https://github.com/Microsoft/mwt-ds/raw/master/images/MWT-WhitePaper.pdf","alts":[],"httpStatus":200},{"url":"https://arxiv.org/pdf/1103.4601.pdf","alts":[],"httpStatus":200},{"url":"https://blog.iterable.com/why-you-should-become-a-multi-armed-bandit-1cb6651063f5","alts":[{"type":2,"url":"medium://p/1cb6651063f5"},{"type":3,"url":"medium://p/1cb6651063f5"}],"httpStatus":200},{"url":"https://becominghuman.ai/jeff-deans-talk-on-large-scale-deep-learning-171fb8c8ac57","alts":[{"type":2,"url":"medium://p/171fb8c8ac57"},{"type":3,"url":"medium://p/171fb8c8ac57"}],"httpStatus":200},{"url":"http://pavel.surmenok.com/2017/08/26/contextual-bandits-and-reinforcement-learning/","alts":[],"httpStatus":200},{"url":"http://videolectures.net/kdd2010_beygelzimer_langford_lte/","alts":[],"httpStatus":200}],"version":"0.3","generatedAt":1508293725538},"isLockedPreviewOnly":false,"takeoverId":"","metaDescription":"","totalClapCount":200,"sectionCount":9,"readingList":0},"coverless":true,"slug":"contextual-bandits-and-reinforcement-learning","translationSourcePostId":"","translationSourceCreatorId":"","isApprovedTranslation":false,"inResponseToPostId":"","inResponseToRemovedAt":0,"isTitleSynthesized":true,"allowResponses":true,"importedUrl":"","importedPublishedAt":0,"visibility":0,"uniqueSlug":"contextual-bandits-and-reinforcement-learning-6bdfeaece72a","previewContent":{"bodyModel":{"paragraphs":[{"name":"previewImage","type":4,"text":"","layout":10,"metadata":{"id":"1*FH4t-DcuKWfLYRWvd4JIjA.png","originalWidth":586,"originalHeight":465,"isFeatured":true}},{"name":"4dc5","type":3,"text":"Contextual Bandits and Reinforcement Learning","markups":[],"alignment":1},{"name":"d2fa","type":1,"text":"If you develop personalization of user experience for your website or an app…","markups":[],"alignment":1}],"sections":[{"startIndex":0}]},"isFullContent":false},"license":0,"inResponseToMediaResourceId":"","canonicalUrl":"https://towardsdatascience.com/contextual-bandits-and-reinforcement-learning-6bdfeaece72a","approvedHomeCollectionId":"7f60cf5620c9","approvedHomeCollection":{"id":"7f60cf5620c9","name":"Towards Data Science","slug":"towards-data-science","tags":["DATA SCIENCE","MACHINE LEARNING","ARTIFICIAL INTELLIGENCE","BIG DATA","ANALYTICS"],"creatorId":"895063a310f4","description":"Sharing concepts, ideas, and codes.","shortDescription":"Sharing concepts, ideas, and codes.","image":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":71898,"activeAt":1524662731882},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"memberOfMembershipPlanId":"","isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"twitterUsername":"TDataScience","facebookPageName":"towardsdatascience","publicEmail":"publication@towardsdatascience.com","collectionMastheadId":"8b6aceffde6","domain":"towardsdatascience.com","sections":[{"type":2,"collectionHeaderMetadata":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5}},{"type":1,"postListMetadata":{"source":4,"layout":2,"number":1,"postIds":[],"tagSlug":"Towards Data Science"}},{"type":1,"postListMetadata":{"source":1,"layout":4,"number":6,"postIds":[],"sectionHeader":"Latest"}},{"type":3,"promoMetadata":{"sectionHeader":"","promoId":"39ecad7f281"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["e82cfba4d9c2","7a75effe7cc"],"sectionHeader":"Our Letters"}},{"type":3,"promoMetadata":{"sectionHeader":"","promoId":"dbabc89840b7"}},{"type":1,"postListMetadata":{"source":2,"layout":7,"number":7,"postIds":[],"sectionHeader":"Trending"}},{"type":3,"promoMetadata":{"sectionHeader":"","promoId":"69b26f0f1e35"}},{"type":1,"postListMetadata":{"source":4,"layout":4,"number":9,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Editors' Picks"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":3,"postIds":["16d776fd34bd","378cbd5e5c85","e7e681d4f03f"],"sectionHeader":"Companies That Support Us"}},{"type":3,"promoMetadata":{"sectionHeader":"","promoId":"8b04cd40f0c8"}},{"type":1,"postListMetadata":{"source":4,"layout":5,"number":3,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Last Chance To Read"}}],"tintColor":"#FF355876","lightText":true,"favicon":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF668AAA","point":0},{"color":"#FF61809D","point":0.1},{"color":"#FF5A7690","point":0.2},{"color":"#FF546C83","point":0.3},{"color":"#FF4D6275","point":0.4},{"color":"#FF455768","point":0.5},{"color":"#FF3D4C5A","point":0.6},{"color":"#FF34414C","point":0.7},{"color":"#FF2B353E","point":0.8},{"color":"#FF21282F","point":0.9},{"color":"#FF161B1F","point":1}],"backgroundColor":"#FFFFFFFF"},"tintBackgroundSpectrum":{"colorPoints":[{"color":"#FF355876","point":0},{"color":"#FF4D6C88","point":0.1},{"color":"#FF637F99","point":0.2},{"color":"#FF7791A8","point":0.3},{"color":"#FF8CA2B7","point":0.4},{"color":"#FF9FB3C6","point":0.5},{"color":"#FFB2C3D4","point":0.6},{"color":"#FFC5D2E1","point":0.7},{"color":"#FFD7E2EE","point":0.8},{"color":"#FFE9F1FA","point":0.9},{"color":"#FFFBFFFF","point":1}],"backgroundColor":"#FF355876"},"highlightSpectrum":{"colorPoints":[{"color":"#FFEDF4FC","point":0},{"color":"#FFE9F2FD","point":0.1},{"color":"#FFE6F1FD","point":0.2},{"color":"#FFE2EFFD","point":0.3},{"color":"#FFDFEEFD","point":0.4},{"color":"#FFDBECFE","point":0.5},{"color":"#FFD7EBFE","point":0.6},{"color":"#FFD4E9FE","point":0.7},{"color":"#FFD0E7FF","point":0.8},{"color":"#FFCCE6FF","point":0.9},{"color":"#FFC8E4FF","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[{"type":4,"title":"Data Science","url":"https://towardsdatascience.com/data-science/home","topicId":"cf416843aadc","source":"topicId"},{"type":4,"title":"Machine Learning","url":"https://towardsdatascience.com/machine-learning/home","topicId":"a5c9b2f1cb6b","source":"topicId"},{"type":4,"title":"Programming","url":"https://towardsdatascience.com/programming/home","topicId":"41533a1dc73c","source":"topicId"},{"type":4,"title":"Visualization","url":"https://towardsdatascience.com/data-visualization/home","topicId":"825e6cb8b9ce","source":"topicId"},{"type":4,"title":"Picks","url":"https://towardsdatascience.com/editors-picks/home","topicId":"e81f4fc5ee6b","source":"topicId"},{"type":4,"title":"Contribute","url":"https://towardsdatascience.com/contribute/home","topicId":"6ae0c8697d8c","source":"topicId"}],"colorBehavior":2,"instantArticlesState":0,"acceleratedMobilePagesState":0,"googleAnalyticsId":"UA-19707169-24","ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5},"paidForDomainAt":1509037374118,"type":"Collection"},"newsletterId":"","webCanonicalUrl":"https://towardsdatascience.com/contextual-bandits-and-reinforcement-learning-6bdfeaece72a","mediumUrl":"https://towardsdatascience.com/contextual-bandits-and-reinforcement-learning-6bdfeaece72a","migrationId":"","notifyFollowers":true,"notifyTwitter":false,"isSponsored":false,"isRequestToPubDisabled":false,"notifyFacebook":false,"responseHiddenOnParentPostAt":0,"isSeries":false,"isSubscriptionLocked":false,"seriesLastAppendedAt":0,"audioVersionDurationSec":0,"sequenceId":"","isNsfw":false,"isEligibleForRevenue":false,"isBlockedFromHightower":false,"deletedAt":0,"lockedPostSource":0,"hightowerMinimumGuaranteeStartsAt":0,"hightowerMinimumGuaranteeEndsAt":0,"featureLockRequestAcceptedAt":0,"featureLockRequestMinimumGuaranteeAmount":0,"isElevate":false,"mongerRequestType":1,"type":"Post"},"mentionedUsers":[],"collaborators":[],"membershipPlans":[],"collectionUserRelations":[],"mode":null,"references":{"User":{"d002f056f8c":{"userId":"d002f056f8c","name":"Pavel Surmenok","username":"surmenok","createdAt":1443043369304,"lastPostCreatedAt":1522450062156,"imageId":"0*Er1PaJU1KWzERL6w.jpeg","backgroundImageId":"","bio":"Engineering Manager at JustAnswer. Machine learning engineering and chatbots. All opinions are my own.","twitterScreenName":"surmenok","socialStats":{"userId":"d002f056f8c","usersFollowedCount":347,"usersFollowedByCount":1638,"type":"SocialStats"},"social":{"userId":"lo_sL5hrCPWk201","targetUserId":"d002f056f8c","type":"Social"},"facebookAccountId":"970668082998286","allowNotes":1,"isNsfw":false,"type":"User"}},"Collection":{"7f60cf5620c9":{"id":"7f60cf5620c9","name":"Towards Data Science","slug":"towards-data-science","tags":["DATA SCIENCE","MACHINE LEARNING","ARTIFICIAL INTELLIGENCE","BIG DATA","ANALYTICS"],"creatorId":"895063a310f4","description":"Sharing concepts, ideas, and codes.","shortDescription":"Sharing concepts, ideas, and codes.","image":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"metadata":{"followerCount":71898,"activeAt":1524662731882},"virtuals":{"permissions":{"canPublish":false,"canPublishAll":false,"canRepublish":false,"canRemove":false,"canManageAll":false,"canSubmit":false,"canEditPosts":false,"canAddWriters":false,"canViewStats":false,"canSendNewsletter":false,"canViewLockedPosts":false,"canViewCloaked":false,"canEditOwnPosts":false,"canBeAssignedAuthor":false,"canEnrollInHightower":false,"canLockPostsForMediumMembers":false},"isSubscribed":false,"isNewsletterSubscribed":false,"memberOfMembershipPlanId":"","isEnrolledInHightower":false,"isEligibleForHightower":false},"logo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"twitterUsername":"TDataScience","facebookPageName":"towardsdatascience","publicEmail":"publication@towardsdatascience.com","collectionMastheadId":"8b6aceffde6","domain":"towardsdatascience.com","sections":[{"type":2,"collectionHeaderMetadata":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5}},{"type":1,"postListMetadata":{"source":4,"layout":2,"number":1,"postIds":[],"tagSlug":"Towards Data Science"}},{"type":1,"postListMetadata":{"source":1,"layout":4,"number":6,"postIds":[],"sectionHeader":"Latest"}},{"type":3,"promoMetadata":{"sectionHeader":"","promoId":"39ecad7f281"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":2,"postIds":["e82cfba4d9c2","7a75effe7cc"],"sectionHeader":"Our Letters"}},{"type":3,"promoMetadata":{"sectionHeader":"","promoId":"dbabc89840b7"}},{"type":1,"postListMetadata":{"source":2,"layout":7,"number":7,"postIds":[],"sectionHeader":"Trending"}},{"type":3,"promoMetadata":{"sectionHeader":"","promoId":"69b26f0f1e35"}},{"type":1,"postListMetadata":{"source":4,"layout":4,"number":9,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Editors' Picks"}},{"type":1,"postListMetadata":{"source":3,"layout":4,"number":3,"postIds":["16d776fd34bd","378cbd5e5c85","e7e681d4f03f"],"sectionHeader":"Companies That Support Us"}},{"type":3,"promoMetadata":{"sectionHeader":"","promoId":"8b04cd40f0c8"}},{"type":1,"postListMetadata":{"source":4,"layout":5,"number":3,"postIds":[],"tagSlug":"Towards Data Science","sectionHeader":"Last Chance To Read"}}],"tintColor":"#FF355876","lightText":true,"favicon":{"imageId":"1*F0LADxTtsKOgmPa-_7iUEQ.jpeg","filter":"","backgroundSize":"","originalWidth":1275,"originalHeight":1275,"strategy":"resample","height":0,"width":0},"colorPalette":{"defaultBackgroundSpectrum":{"colorPoints":[{"color":"#FF668AAA","point":0},{"color":"#FF61809D","point":0.1},{"color":"#FF5A7690","point":0.2},{"color":"#FF546C83","point":0.3},{"color":"#FF4D6275","point":0.4},{"color":"#FF455768","point":0.5},{"color":"#FF3D4C5A","point":0.6},{"color":"#FF34414C","point":0.7},{"color":"#FF2B353E","point":0.8},{"color":"#FF21282F","point":0.9},{"color":"#FF161B1F","point":1}],"backgroundColor":"#FFFFFFFF"},"tintBackgroundSpectrum":{"colorPoints":[{"color":"#FF355876","point":0},{"color":"#FF4D6C88","point":0.1},{"color":"#FF637F99","point":0.2},{"color":"#FF7791A8","point":0.3},{"color":"#FF8CA2B7","point":0.4},{"color":"#FF9FB3C6","point":0.5},{"color":"#FFB2C3D4","point":0.6},{"color":"#FFC5D2E1","point":0.7},{"color":"#FFD7E2EE","point":0.8},{"color":"#FFE9F1FA","point":0.9},{"color":"#FFFBFFFF","point":1}],"backgroundColor":"#FF355876"},"highlightSpectrum":{"colorPoints":[{"color":"#FFEDF4FC","point":0},{"color":"#FFE9F2FD","point":0.1},{"color":"#FFE6F1FD","point":0.2},{"color":"#FFE2EFFD","point":0.3},{"color":"#FFDFEEFD","point":0.4},{"color":"#FFDBECFE","point":0.5},{"color":"#FFD7EBFE","point":0.6},{"color":"#FFD4E9FE","point":0.7},{"color":"#FFD0E7FF","point":0.8},{"color":"#FFCCE6FF","point":0.9},{"color":"#FFC8E4FF","point":1}],"backgroundColor":"#FFFFFFFF"}},"navItems":[{"type":4,"title":"Data Science","url":"https://towardsdatascience.com/data-science/home","topicId":"cf416843aadc","source":"topicId"},{"type":4,"title":"Machine Learning","url":"https://towardsdatascience.com/machine-learning/home","topicId":"a5c9b2f1cb6b","source":"topicId"},{"type":4,"title":"Programming","url":"https://towardsdatascience.com/programming/home","topicId":"41533a1dc73c","source":"topicId"},{"type":4,"title":"Visualization","url":"https://towardsdatascience.com/data-visualization/home","topicId":"825e6cb8b9ce","source":"topicId"},{"type":4,"title":"Picks","url":"https://towardsdatascience.com/editors-picks/home","topicId":"e81f4fc5ee6b","source":"topicId"},{"type":4,"title":"Contribute","url":"https://towardsdatascience.com/contribute/home","topicId":"6ae0c8697d8c","source":"topicId"}],"colorBehavior":2,"instantArticlesState":0,"acceleratedMobilePagesState":0,"googleAnalyticsId":"UA-19707169-24","ampLogo":{"imageId":"","filter":"","backgroundSize":"","originalWidth":0,"originalHeight":0,"strategy":"resample","height":0,"width":0},"header":{"title":"Towards Data Science","description":"Sharing concepts, ideas, and codes","backgroundImage":{},"logoImage":{},"alignment":2,"layout":5},"paidForDomainAt":1509037374118,"type":"Collection"}},"Social":{"d002f056f8c":{"userId":"lo_sL5hrCPWk201","targetUserId":"d002f056f8c","type":"Social"}},"SocialStats":{"d002f056f8c":{"userId":"d002f056f8c","usersFollowedCount":347,"usersFollowedByCount":1638,"type":"SocialStats"}}}})
// ]]></script><div class="surface-scrollOverlay"></div><script charset="UTF-8" src="Contextual%20Bandits%20and%20Reinforcement%20Learning%20%E2%80%93%20Towards%20Data%20Science_files/main-common-async.js"></script><script charset="UTF-8" src="Contextual%20Bandits%20and%20Reinforcement%20Learning%20%E2%80%93%20Towards%20Data%20Science_files/main-notes.js"></script></body></html>